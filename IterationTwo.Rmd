---
title: "MPS Project -- Iteration 2"
author: "Sung-Woo Ahn Wanwen Gu Yvonne Liu Xinyue Chen"
date: "April 5, 2019"
output: 
  html_document:
    highlight: pygments
    theme: cosmo
---

<style type="text/css">

body{ /* Normal  */
      font-size: 18px;
  }

</style>



## Import dataset
```{r warning=FALSE, message=FALSE, error=FALSE}
library(knitr)
library(data.table)
library(bit64)
library(Rmpfr)
library(tidyverse)
library(kableExtra)
library(VIM)
library(DT)
library(e1071)
library(mlbench)
library(corrplot)
library(bnlearn)
library(gridExtra)
library(plotly)
library(MLmetrics)
```
```{r}
versions<-sessionInfo()
versions
```
```{r echo=FALSE}
options(kableExtra.latex.load_packages = FALSE)
knit_hooks$set(document = function(x) {
  sub('\\usepackage[]{color}', '\\usepackage[]{xcolor}', x, fixed = TRUE)
})

```


```{r}
train.final<-fread('training_final.csv', header=T, integer64='character')
valid.final<-fread('validation_final.csv',header=T, integer64='character')
train.NoNANoM<-fread('training_NoNA_NoMultc.csv', header = T, integer64 = 'character')
valid.NoNANoM<-fread('validation_NoNA_NoMultc.csv', header = T, integer64 = 'character')

#match two datasets
# valid.final<-valid.final[,-4]
# train.final<-train.final[, -11]
```


## Naive Bayes: Start with small subset of features

### Count.app, count_event, weekday, group
```{r}
#features: count.app, count_event, weekday, group
train1<-cbind(train.final[,6], train.final[,5], train.final[,37], train.final[,2])
valid1<-cbind(valid.final[,6], valid.final[,5], valid.final[,37], valid.final[,2])
fit1<-naiveBayes(as.factor(group)~., data=train1)
valid1$group<-as.factor(valid1$group)
pred1<-predict(fit1, valid1)
pred1probs<-predict(fit1, valid1, type ='raw')
summary(pred1)
# F23- F24-26 F27-28 F29-32 F33-42   F43+   M22- M23-26 M27-28 M29-31 M32-38   M39+ 
#1566      0      0      0      0      0   2136    283      9      0    428    231 
mean(pred1!=valid1$group)
#[1] 0.9024285

#log-loss
pred1probsdat <- data.frame(valid1$group, pred1probs)
logloss <- vector(length = length(pred1probsdat$valid1.group))
clas<-vector(length = length(pred1probsdat$valid1.group))
for (i in 1:length(pred1probsdat$valid1.group)) {
  clas=grep(str_split(paste(pred1probsdat$valid1.group[i]), '-|\\+')[[1]][1], names(pred1probsdat))
  logloss[i] = log(pred1probsdat[i,clas])
}
-mean(logloss)
```
```{r}
confusion1 <- as.data.frame(table(pred1, valid1$group))
p<-ggplot(confusion1, aes(Var2, pred1)) +
  geom_tile(aes(fill = Freq), colour='gray') +
  scale_fill_gradient(low='antiquewhite', high = 'purple') +
  theme(axis.text.x = element_text(angle = 80, hjust = 1, size = 9),
        axis.text.y = element_text(size = 9),
        axis.title = element_text(size = 10),
        plot.title = element_text(size = 12)) +
  labs(x= 'Observed', y= 'Predicted', title = 'Confusion Matrix')
p
```

### Count.app, count_event, weekday, group, 2016-04-30 -- 2016-05-07
```{r}
#features: count.app, count_event, weekday, group, 2016-04-30--2016-05-07
train2<-cbind(train1, train.final[, c(seq(29, 36))])
valid2<-cbind(valid1, valid.final[, c(seq(29, 36))])
fit2<-naiveBayes(as.factor(group)~., data=train2)
valid2$group<-as.factor(valid2$group)
pred2<-predict(fit2, valid2)
summary(pred2)
#F23- F24-26 F27-28 F29-32 F33-42   F43+   M22- M23-26 M27-28 M29-31 M32-38   M39+ 
#3813      0      0     35     44     74    213    105     20     46     63    240  
mean(pred2!=valid2$group)
# 0.9204814

#log-loss
pred2probs <-predict(fit2, valid2, type = 'raw')
pred2probsdat <- data.frame(valid2$group, pred2probs)
logloss <- vector(length = length(pred2probsdat$valid2.group))
for (i in 1:length(pred2probsdat$valid2.group)) {
  clas=grep(str_split(paste(pred2probsdat$valid2.group[i]), '-|\\+')[[1]][1], names(pred2probsdat))
  logloss[i] = log(pred2probsdat[i,clas])
}
-mean(logloss)
-mean(logloss[is.infinite(logloss)==FALSE])
```
Adding the date features made the classifications worse

### Count.app, count_event, weekday, group, count.4_8 -- count.20-24
```{r}
#features: count.app, count_event, weekday, group, count.4_8, count.8_12, count.12_16, count.16-20, count.20-24
train3<-cbind(train1, train.final[, c(seq(38, 42))])
valid3<-cbind(valid1, valid.final[, c(seq(38, 42))])
fit3<-naiveBayes(as.factor(group)~., data=train3)
valid3$group<-as.factor(valid3$group)
pred3<-predict(fit3, valid3)
summary(pred3)
#F23- F24-26 F27-28 F29-32 F33-42   F43+   M22- M23-26 M27-28 M29-31 M32-38   M39+ 
#78      0      2     45      8     45   3874    168     23      8    190    212 
mean(pred3!=valid3$group)
#0.9065119

#log-loss
pred3probs <-predict(fit3, valid3, type = 'raw')
pred3probsdat <- data.frame(valid3$group, pred3probs)
logloss <- vector(length = length(pred3probsdat$valid3.group))
for (i in 1:length(pred3probsdat$valid3.group)) {
  clas=grep(str_split(paste(pred3probsdat$valid3.group[i]), '-|\\+')[[1]][1], names(pred3probsdat))
  logloss[i] = log(pred3probsdat[i,clas])
}
-mean(logloss)
-mean(logloss[is.infinite(logloss)==FALSE])
```
Adding the hourly time features made the classifications worse

### Count.app, count_event, weekday, group, count.pc
```{r}
#features: count.app, count_event, weekday, group, count.pc
train4<-cbind(train1, train.final[, c(seq(20, 28))])
valid4<-cbind(valid1, valid.final[, c(seq(20, 28))])
fit4<-naiveBayes(as.factor(group)~., data=train4)
valid4$group<-as.factor(valid4$group)
pred4<-predict(fit4, valid4)
summary(pred4)
#F23- F24-26 F27-28 F29-32 F33-42   F43+   M22- M23-26 M27-28 M29-31 M32-38   M39+ 
# 118      2   3561      1    195    246      2     12     48     79     17    372  
mean(pred4!=valid4$group)
#0.9314421

#log-loss
pred4probs <-predict(fit4, valid4, type = 'raw')
pred4probsdat <- data.frame(valid4$group, pred4probs)
logloss <- vector(length = length(pred4probsdat$valid4.group))
for (i in 1:length(pred4probsdat$valid4.group)) {
  clas=grep(str_split(paste(pred4probsdat$valid4.group[i]), '-|\\+')[[1]][1], names(pred4probsdat))
  logloss[i] = log(pred4probsdat[i,clas])
}
-mean(logloss)
-mean(logloss[is.infinite(logloss)==FALSE])
```

### count.app, count_event, weekday, group, ratio.pc
```{r}
#features:  count.app, count_event, weekday, group, ratio.pc
train5<-cbind(train1, train.final[, c(seq(16, 28))])
valid5<-cbind(valid1, valid.final[, c(seq(16, 28))])
fit5<-naiveBayes(as.factor(group)~., data=train5)
valid5$group<-as.factor(valid5$group)
pred5<-predict(fit5, valid5)
summary(pred5)
# F23- F24-26 F27-28 F29-32 F33-42   F43+   M22- M23-26 M27-28 M29-31 M32-38   M39+ 
# 3189      5    618     30     14    192     69    141     44     39    207    105 
mean(pred5!=valid5$group)
# 0.9228455

#log-loss
pred5probs <-predict(fit5, valid5, type = 'raw')
pred5probsdat <- data.frame(valid5$group, pred5probs)
logloss <- vector(length = length(pred5probsdat$valid5.group))
for (i in 1:length(pred5probsdat$valid5.group)) {
  clas=grep(str_split(paste(pred5probsdat$valid5.group[i]), '-|\\+')[[1]][1], names(pred5probsdat))
  logloss[i] = log(pred5probsdat[i,clas])
}
-mean(logloss)
-mean(logloss[is.infinite(logloss)==FALSE])
```

### count.app, count_event, weekday, group, longitude, latitude
```{r}
#features: count.app, count_event, weekday, group, longitude, latitude
train6<-cbind(train1, train.final[, c(3,4)])
valid6<-cbind(valid1, valid.final[, c(3,4)])
fit6<-naiveBayes(as.factor(group)~., data=train6)
valid6$group<-as.factor(valid6$group)
pred6<-predict(fit6, valid6)
summary(pred6)
#F23- F24-26 F27-28 F29-32 F33-42   F43+   M22- M23-26 M27-28 M29-31 M32-38   M39+ 
#2770      0    154      0     40      0    437    233      9      0    839    171 
mean(pred6!=valid6$group)
# 0.8934021

#log-loss
pred6probs <-predict(fit6, valid6, type = 'raw')
pred6probsdat <- data.frame(valid6$group, pred6probs)
logloss <- vector(length = length(pred6probsdat$valid6.group))
for (i in 1:length(pred6probsdat$valid6.group)) {
  clas=grep(str_split(paste(pred6probsdat$valid6.group[i]), '-|\\+')[[1]][1], names(pred6probsdat))
  logloss[i] = log(pred6probsdat[i,clas])
}
-mean(logloss)
```
The best model is with the features count.app, count_event, weekday, group, longitude, latitude, with missclassification rate of 89.4%.

#try category.indicator
```{r}
#features: category.count
fit7<-naiveBayes(as.factor(group)~., data=indicator_train)
indicator_valid$group<-as.factor(indicator_valid$group)
pred7<-predict(fit7, indicator_valid)
summary(pred7)
#F23- F24-26 F27-28 F29-32 F33-42   F43+   M22- M23-26 M27-28 M29-31 M32-38   M39+ 
#0      0      0      0     0       2487   468    0      236    1454    4      0
mean(pred7!=indicator_valid$group)
# 0.9024285

#log-loss
pred7probs <-predict(fit7, indicator_valid, type = 'raw')
pred7probsdat <- data.frame(indicator_valid$group, pred7probs)
logloss <- vector(length = length(pred7probsdat$indicator_valid.group))
for (i in 1:length(pred7probsdat$indicator_valid.group)) {
  clas=grep(str_split(paste(pred7probsdat$indicator_valid.group[i]), '-|\\+')[[1]][1], names(pred7probsdat))
  logloss[i] = log(pred7probsdat[i,clas])
}
-mean(logloss)
# 5.883481
```

## Possible Causes of the Misclassifications

### Check the Independence Assumption
```{r fig.height=14, fig.width=14}
train.final$group <- as.factor(train.final$group)
corr <- cor(train.final[,-c(1,2,43,44)])
corrplot(corr, order = "hclust", type = 'lower', tl.col = 'black', tl.srt = 45)

corrM <- cor(train.NoNANoM[,-c(1,2,66,67)])
corrplot(corrM, type = 'lower', tl.col = 'black', tl.srt = 45)
```
We can see from these two plots that there are some significant correlations between the features. The date features are all correlated with each other.

### Check the Distributions: Are they really Normal?
```{r fig.height=10, fig.width=12}
ggplot(data = train.final, aes(x = count_event, fill = group)) +
  geom_histogram(binwidth = 10) +
  scale_fill_manual(values=c("#F44336", "#E91E63", "#9C27B0", "#673AB7", "#3F51B5", "#2196F3", "#03A9F4", "#00BCD4", "#009688", "#4CAF50", "#8BC34A", "#CDDC39")) +
  xlim(c(0,250)) +
  ggtitle("Event Count")

ggplot(data = train.final, aes(x = count.app, fill = group)) +
  geom_histogram(binwidth = 10) +
  scale_fill_manual(values=c("#F44336", "#E91E63", "#9C27B0", "#673AB7", "#3F51B5", "#2196F3", "#03A9F4", "#00BCD4", "#009688", "#4CAF50", "#8BC34A", "#CDDC39")) +
  xlim(c(0,250)) +
  ggtitle("App Count")

ggplot(data = train.final, aes(x = longitude)) +
  geom_histogram(binwidth = 10) +
  xlim(c(0,750)) +
  ggtitle("Longitude")

ggplot(data = train.final, aes(x = latitude)) +
  geom_histogram(binwidth = 10) +
  xlim(c(0,750)) +
  ggtitle("Latitude")

ggplot(data = train.final, aes(x = weekday)) +
  geom_histogram(binwidth = 10) +
  xlim(c(0,750)) +
  ggtitle("Weekday")

countPCgraphs <- map(names(train.final[,7:15]), ~ggplot(data=train.final, aes_string(x=.x))+ xlim(c(-7,7)) +
  geom_histogram(binwidth = .05))

marrangeGrob(countPCgraphs, ncol=2, nrow = 3)

ratioPCgraphs <- map(names(train.final[,16:28]), ~ggplot(data=train.final, aes_string(x=.x))+ xlim(c(-7,7)) +
  geom_histogram(binwidth = .05))

marrangeGrob(ratioPCgraphs, ncol=2, nrow = 3)
```

```{r fig.height=10, fig.width=12, warning=FALSE}
names(train.NoNANoM)[c(24,46)] <- c("socialnetworking.appct", "socialnetworking.isactiveRat")
graphs3 <- map(names(train.NoNANoM[,-c(1,2,3,4,66,67)]), ~ggplot(data=train.NoNANoM, aes_string(x=.x))+
  geom_histogram())

marrangeGrob(graphs3, ncol=2, nrow = 3)
```

- The principal components are actually Gaussian.
- The event count, app count, and weekdays are all heavily skewed. Since these are count features, we should perhaps be using the multinomial distribution instead.


$$P(F23-|features)=\frac{P(feature1|F23-)*P(feature2|F23-)*\cdots *P(feature43|F23-)*P(F23-)}{P(features)}$$

### Check between group distribution
```{r}
# Compare the predictions with the actual probabilities
pred1<-predict(fit1, valid1)
predictions1 <- data.frame(pred1, pred1probs)
predictions1 <- predictions1[,c("pred1", "M22.", "F23.", "F24.26")]

# Compare the group predictions with the feature values
valid1vars <- valid.final[,c("count.app", "count_event", "weekday")]
predictions1 <- cbind(valid1$group, predictions1, valid1vars)
```
```{r}
kable(predictions1[1:15,], caption = 'Predictions') %>%
  kable_styling(bootstrap_options = c("striped", "bordered", "responsive", "condensed"), full_width = F)
```
```{r}
# Look at the mean and sd of the gaussian distribution it is using
distrs <- cbind(fit1$tables$count.app, fit1$tables$count_event, fit1$tables$weekday)
colnames(distrs)<-c("count.appmean", "count.appsd", "count_eventmean", "count_eventsd", "weekdaymean", "weekdaysd")

# Now lot the Normal distributions
# Distribution of the App Count
caseqs <- matrix(nrow=100,ncol=12)
ecseqs <- matrix(nrow=100,ncol=12)
weseqs <- matrix(nrow=100,ncol=12)
cadists <- matrix(nrow=100,ncol=12)
ecdists <- matrix(nrow=100,ncol=12)
wedists <- matrix(nrow=100,ncol=12)

for (i in 1:12) {
  caseqs[,i]<-seq(distrs[i,1]-4*distrs[i,2],distrs[i,1]+4*distrs[i,2], length=100)
  cadists[,i]<-dnorm(caseqs[,i],mean = distrs[i,1], sd=distrs[i,2])
  
  ecseqs[,i]<-seq(distrs[i,3]-4*distrs[i,4],distrs[i,3]+4*distrs[i,4], length=100)
  ecdists[,i]<-dnorm(ecseqs[,i],mean = distrs[i,3], sd=distrs[i,4])
  
  weseqs[,i]<-seq(distrs[i,5]-4*distrs[i,6],distrs[i,5]+4*distrs[i,6], length=100)
  wedists[,i]<-dnorm(weseqs[,i],mean = distrs[i,5], sd=distrs[i,6])
}

caseqs<-c(caseqs[,1], caseqs[,2], caseqs[,3], caseqs[,4], caseqs[,5], caseqs[,6], caseqs[,7], caseqs[,8], caseqs[,9], caseqs[,10], caseqs[,11], caseqs[,12])

caseqs<- data.frame('x'=caseqs, 'group'=c(rep(fit1$levels[1], 100), rep(fit1$levels[2], 100), rep(fit1$levels[3], 100), rep(fit1$levels[4], 100), rep(fit1$levels[5], 100), rep(fit1$levels[6], 100), rep(fit1$levels[7], 100), rep(fit1$levels[8], 100), rep(fit1$levels[9], 100), rep(fit1$levels[10], 100), rep(fit1$levels[11], 100), rep(fit1$levels[12], 100)))

caseqs$y <- c(cadists[,1], cadists[,2], cadists[,3], cadists[,4], cadists[,5], cadists[,6], cadists[,7], cadists[,8], cadists[,9], cadists[,10], cadists[,11], cadists[,12])

ecseqs<-c(ecseqs[,1], ecseqs[,2], ecseqs[,3], ecseqs[,4], ecseqs[,5], ecseqs[,6], ecseqs[,7], ecseqs[,8], ecseqs[,9], ecseqs[,10], ecseqs[,11], ecseqs[,12])

ecseqs<- data.frame('x'=ecseqs, 'group'=c(rep(fit1$levels[1], 100), rep(fit1$levels[2], 100), rep(fit1$levels[3], 100), rep(fit1$levels[4], 100), rep(fit1$levels[5], 100), rep(fit1$levels[6], 100), rep(fit1$levels[7], 100), rep(fit1$levels[8], 100), rep(fit1$levels[9], 100), rep(fit1$levels[10], 100), rep(fit1$levels[11], 100), rep(fit1$levels[12], 100)))

ecseqs$y <- c(ecdists[,1], ecdists[,2], ecdists[,3], ecdists[,4], ecdists[,5], ecdists[,6], ecdists[,7], ecdists[,8], ecdists[,9], ecdists[,10], ecdists[,11], ecdists[,12])


weseqs<-c(weseqs[,1], weseqs[,2], weseqs[,3], weseqs[,4], weseqs[,5], weseqs[,6], weseqs[,7], weseqs[,8], weseqs[,9], weseqs[,10], weseqs[,11], weseqs[,12])

weseqs<- data.frame('x'=weseqs, 'group'=c(rep(fit1$levels[1], 100), rep(fit1$levels[2], 100), rep(fit1$levels[3], 100), rep(fit1$levels[4], 100), rep(fit1$levels[5], 100), rep(fit1$levels[6], 100), rep(fit1$levels[7], 100), rep(fit1$levels[8], 100), rep(fit1$levels[9], 100), rep(fit1$levels[10], 100), rep(fit1$levels[11], 100), rep(fit1$levels[12], 100)))

weseqs$y <- c(wedists[,1], wedists[,2], wedists[,3], wedists[,4], wedists[,5], wedists[,6], wedists[,7], wedists[,8], wedists[,9], wedists[,10], wedists[,11], wedists[,12])


ggplot(caseqs, aes(x=x,y=y, color=group)) +
  geom_point(position = 'jitter') +
  ggtitle('App Count')

ggplot(ecseqs, aes(x=x,y=y, color=group)) +
  geom_point(position = 'jitter') +
  ggtitle('Event Count')

ggplot(weseqs, aes(x=x,y=y, color=group)) +
  geom_point(position = 'jitter') +
  ggtitle('Weekday Count')
```


```{r fig.height=8, fig.width=7, warning=FALSE}
a<-ggplot(train.final, aes(x=group, y=count_event)) + 
  geom_jitter(position=position_jitter(0.2)) +
  ylim(c(0,1000))

b<-ggplot(train.final, aes(x=group, y=count.app)) + 
  geom_jitter(position=position_jitter(0.2))

grid.arrange(a,b, ncol=1)
```
```{r fig.height=10, fig.width=12, warning=FALSE}
graphs <- map(names(train.final[,-c(1,2,43,44)]), ~ggplot(data=train.final, aes_string(x='group', y=.x))+
  geom_jitter(position = position_jitter(.2)))

marrangeGrob(graphs, ncol=2, nrow = 3)
```


```{r fig.height=10, fig.width=12, warning=FALSE}
names(train.NoNANoM)[c(24,46)] <- c("socialnetworking.appct", "socialnetworking.isactiveRat")
graphs2 <- map(names(train.NoNANoM[,-c(1,2,3,4,66,67)]), ~ggplot(data=train.NoNANoM, aes_string(x='group', y=.x))+
  geom_jitter(position = position_jitter(.2), na.rm = TRUE))

marrangeGrob(graphs2, ncol=2, nrow = 3)
```
We can see that our features are actually do not really differ between groups. The distributions are too similar to find clear classification boundaries.

```{r fig.width=10, fig.height=10}
ggplot(data = train.final) +
  geom_point(aes(x=count_event, y = count.app, color=group)) +
  xlim(c(0,800))

plot_ly(train.NoNANoM, x = ~count_event, y = ~business.appCt, z = ~weekday, color = ~group) %>%
  add_markers() %>%
  layout(scene = list(xaxis = list(title = 'count_event', range=c(0,500)),
                     yaxis = list(title = 'business.appCt', range=c(0,400)),
                     zaxis = list(title = 'weekday', range=c(0,500))))
```

## Potential Remedies

### Transformation?
```{r}
ggplot(data=train.NoNANoM, aes_string(x='group', y='business.appCt'))+
  geom_jitter(position = position_jitter(.2), na.rm = TRUE) +
  ylim(c(0,900))
```
If we zoom in onto a smaller subsection of app count, there does seem to be some variation. In the female groups, there are generally more smaller numbers, while the male groups generally seem to have higher count numbers. Naive Bayes however doesn't seem to pick this up. Maybe engineer a different feature that can pick this up. If we make these counts into categorical features, binning the counts into low, medium, and high, the Naive Bayes may be able to pick up more differences.

###Try all features
```{r}
traintotal <- train.NoNANoM[,-c(1,3,4,66,67)]
validtotal <- valid.NoNANoM[,-c(1,3,4,66,67)]
traintotal$group <- as.factor(traintotal$group)
validtotal$group <- as.factor(validtotal$group)

fitnb<-naiveBayes(group~., data=traintotal)
prednb<-predict(fitnb, validtotal)
summary(prednb)
mean(prednb!=validtotal$group)

#log-loss
prednbprobs <-predict(fitnb, validtotal, type = 'raw')
prednbprobsdat <- data.frame(validtotal$group, prednbprobs)
logloss <- vector(length = length(prednbprobsdat$validtotal.group))
for (i in 1:length(prednbprobsdat$validtotal.group)) {
  clas=grep(str_split(paste(prednbprobsdat$validtotal.group[i]), '-')[[1]][1], names(prednbprobsdat))
  logloss[i] = log(prednbprobsdat[i,clas])
}
-mean(logloss)
-mean(logloss[is.infinite(logloss)==FALSE])

MultiLogLoss(y_pred = prednbprobs, y_true = validtotal$group)
```



### Try creating categorical features
```{r}
# Obtain the app count features we want to bin
training <- as.data.frame(train.NoNANoM[,7:29])
# Stack the app count features into one long vector
counts <- stack(training)
# Calculate the quantiles
quantiles <- quantile(counts[,1], c(.14,.2857,.4286,.5714,.7143,.8571))
quantiles

# Construct the categorical features based on the quantiles
# training[training==0] <- 0
# training[training>0 & training <= 1] <- 1
# training[training>1 & training <= 14] <- 2
# training[training>14 & training <= 60] <- 3
# training[training>60] <- 4

training[training==0] <- 0
training[training>0 & training <= 1] <- 1
training[training>1 & training <= 14] <- 2
training[training>14 & training <= 27] <- 3
training[training>27 & training <= 70] <- 4
training[training>70] <- 5
# Convert the categorical into factor variables
for (i in 1:23) {
 training[,i] <- as.factor(training[,i]) 
}
for (i in 1:23) {
  names(training)[i] <- paste0(names(training)[i],'cat')
}

# The levels are not consistent across features: make them all 5
for (i in 1:23) {
  training[,i] <- factor(training[,i], levels = c("0","1","2","3","4","5"))
}

# Do the same thing as above to the validation dataset
validation <- as.data.frame(valid.NoNANoM[,7:29])


# validation[validation==0] <- 0
# validation[validation>0 & validation <= 1] <- 1
# validation[validation>1 & validation <= 14] <- 2
# validation[validation>14 & validation <= 60] <- 3
# validation[validation>60] <- 4

validation[validation==0] <- 0
validation[validation>0 & validation <= 1] <- 1
validation[validation>1 & validation <= 14] <- 2
validation[validation>14 & validation <= 27] <- 3
validation[validation>27 & validation <= 70] <- 4
validation[validation>70] <- 5

for (i in 1:23) {
 validation[,i] <- as.factor(validation[,i]) 
}
for (i in 1:23) {
  names(validation)[i] <- paste0(names(validation)[i],'cat')
}

for (i in 1:23) {
  validation[,i] <- factor(validation[,i], levels = c("0","1","2","3","4","5"))
}

validation$group <- valid.NoNANoM$group
training$group <- train.NoNANoM$group
```
```{r}
traincateg<-training
validcateg<-validation
traincateg$group <- as.factor(traincateg$group)
validcateg$group <- as.factor(validcateg$group)
names(traincateg)[18] <- 'socialnetworking.appCtcat'
names(validcateg)[18] <- 'socialnetworking.appCtcat'
fitcateg<-naiveBayes(group~., data=traincateg)
predcateg<-predict(fitcateg, validcateg)
summary(predcateg)
mean(predcateg!=validcateg$group)   # 0.8540726

#log-loss
predcategprobs <-predict(fitcateg, validcateg, type = 'raw')
predcategprobsdat <- data.frame(validcateg$group, predcategprobs)
logloss <- vector(length = length(predcategprobsdat$validcateg.group))
for (i in 1:length(predcategprobsdat$validcateg.group)) {
  clas=grep(str_split(paste(predcategprobsdat$validcateg.group[i]), '-')[[1]][1], names(predcategprobsdat))
  logloss[i] = log(predcategprobsdat[i,clas])
}
-mean(logloss)
# 2.953445

MultiLogLoss(y_pred = predcategprobs, y_true = validcateg$group)
```
```{r}
# Predict gender only
group <- traincateg$group
gender <- substr(group, 1, 1)
traingender <- cbind(traincateg, gender)

group <- validcateg$group
gender <- substr(group, 1, 1)
validgender <- cbind(validcateg, gender)


traingender$gender <- as.factor(traingender$gender)
validgender$gender <- as.factor(validgender$gender)
names(traingender)[18] <- 'socialnetworking.appCt'
names(validgender)[18] <- 'socialnetworking.appCt'
fitgender<-naiveBayes(gender~., data=traingender[,-24])
predgender<-predict(fitgender, validgender[,-24])
summary(predgender)
mean(predgender!=validgender$gender)    # 0.4167204
validgender <- cbind(validgender, gender.predict=predgender)


# predict age further
# separate male and female groups
train.female <- traingender[traingender$gender=='F',]   # 6452
train.male <- traingender[traingender$gender=='M',]     # 12142
valid.female <- validgender[validgender$gender=='F',]   # 1571
valid.male <- validgender[validgender$gender=='M',]     # 3082

# predict age for female
group <- train.female$group
age <- substr(group, 2, 10)
train.female <- cbind(train.female, age)

group <- valid.female$group
age <- substr(group, 2, 10)
valid.female <- cbind(valid.female, age)

train.female$age <- as.factor(train.female$age)
valid.female$age <- as.factor(valid.female$age)

fit.female.age <- naiveBayes(age~., data=train.female[,-c(24,25)])
pred.female.age <- predict(fit.female.age, valid.female[,-c(24,25,26)])
summary(pred.female.age)
mean(pred.female.age!=valid.female$age)    # 0.7536601
valid.female <- cbind(valid.female, age.predict=pred.female.age)


# predict age for female
group <- train.male$group
age <- substr(group, 2, 10)
train.male <- cbind(train.male, age)

group <- valid.male$group
age <- substr(group, 2, 10)
valid.male <- cbind(valid.male, age)

train.male$age <- as.factor(train.male$age)
valid.male$age <- as.factor(valid.male$age)

fit.male.age <- naiveBayes(age~., data=train.male[,-c(24,25)])
pred.male.age <- predict(fit.male.age, valid.male[,-c(24,25,26)])
summary(pred.male.age)
mean(pred.male.age!=valid.male$age)    # 0.7787151
valid.male <- cbind(valid.male, age.predict=pred.male.age)

# overall misclassification rate
valid.gender.age <- rbind(valid.female, valid.male)
group.predict <- paste(valid.gender.age$gender.predict, valid.gender.age$age.predict, sep='')
mean(group.predict!=valid.gender.age$group)    # 0.8540726

```

### Start with all predictors
#### RF
```{r}
library(randomForest)
names(train.NoNANoM)[24] <- "socialnetworking.appCt"
names(train.NoNANoM)[46] <- "socialnetworking.isactiveRat"
names(valid.NoNANoM)[24] <- "socialnetworking.appCt"
names(valid.NoNANoM)[46] <- "socialnetworking.isactiveRat"

traintotal <- cbind(traincateg[,1:23],train.NoNANoM[,-c(1,3,4,66,67)])
validtotal <- cbind(validcateg[,1:23],valid.NoNANoM[,-c(1,3,4,66,67)])
traintotal$group <- as.factor(traintotal$group)
validtotal$group <- as.factor(validtotal$group)
set.seed(1223)
fit.rf <- randomForest(as.factor(group)~., data = traintotal, na.action = na.omit)

rf.pred <- predict(fit.rf, newdata=validtotal)
table(rf.pred, validtotal$group)
mean(rf.pred[is.na(rf.pred)==FALSE]!=validtotal$group[is.na(rf.pred)==FALSE])

predrfprobs <-predict(fit.rf, validtotal, type = 'prob')
predrfprobsdat <- data.frame(validtotal$group, predrfprobs)
logloss <- vector(length = length(predrfprobsdat$validtotal.group))
for (i in 1:length(predrfprobsdat$validtotal.group)) {
  clas=grep(str_split(paste(predrfprobsdat$validtotal.group[i]), '-')[[1]][1], names(predrfprobsdat))
  logloss[i] = log(predrfprobsdat[i,clas])
}
-mean(logloss)

ginis<-importance(fit.rf)
ginis<-data.frame('gini'=ginis[,1], 'categ' = rownames(ginis))
arrange(ginis, desc(gini))
```

### SVM
```{r}
library(e1071)
fit.svm <- svm(as.factor(group) ~ . , traintotal)
pred_svm <- predict(model_svm, validtotal)
mean(as.character(pred_svm) != as.character(validtotal$group))
table(pred_svm, validtotal$group)

predsvmprobs <-predict(fit.svm, validtotal, decision.values = T)
predsvmprobsdat <- data.frame(validtotal$group, predsvmprobs)
logloss <- vector(length = length(predsvmprobsdat$validtotal.group))
for (i in 1:length(predsvmprobsdat$validtotal.group)) {
  clas=grep(str_split(paste(predsvmprobsdat$validtotal.group[i]), '-')[[1]][1], names(predsvmprobsdat))
  logloss[i] = log(predsvmprobsdat[i,clas])
}
-mean(logloss)
```

### Logistic
```{r}
train_log<- traintotal
train_log<-na.omit(train_log)
valid_log<-validtotal
valid_log<-na.omit(valid_log)

require(nnet)
model_log <- multinom(group ~ ., data = traintotal, MaxNWts = 1000000, model = TRUE)
pred_log<-predict(model_log,valid_log)
pred_log_score<-predict (model_log,valid_log, 'probs')
mean(as.character(pred_log) != as.character(valid_log$group))
table(pred_log, valid_log$group)
```



#### Second
```{r}
traintotal <- cbind(traincateg[,-c(16,24)],train.NoNANoM[,-c(1,3,4,66,67)])
validtotal <- cbind(validcateg[,-c(16,24)],valid.NoNANoM[,-c(1,3,4,66,67)])
traintotal$group <- as.factor(traintotal$group)
validtotal$group <- as.factor(validtotal$group)
set.seed(1223)
fit.rf <- randomForest(as.factor(group)~., data = traintotal, na.action = na.omit)

rf.pred <- predict(fit.rf, newdata=validtotal)
table(rf.pred, validtotal$group)
mean(rf.pred[is.na(rf.pred)==FALSE]!=validtotal$group[is.na(rf.pred)==FALSE])

predrfprobs <-predict(fit.rf, validtotal, type = 'prob')
predrfprobsdat <- data.frame(validtotal$group, predrfprobs)
logloss <- vector(length = length(predrfprobsdat$validtotal.group))
for (i in 1:length(predrfprobsdat$validtotal.group)) {
  clas=grep(str_split(paste(predrfprobsdat$validtotal.group[i]), '-')[[1]][1], names(predrfprobsdat))
  logloss[i] = log(predrfprobsdat[i,clas])
}
-mean(logloss)

ginis<-importance(fit.rf)
ginis<-data.frame('gini'=ginis[,1], 'categ' = rownames(ginis))
arrange(ginis, desc(gini))
```


### New Feature Ideas