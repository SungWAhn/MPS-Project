---
title: "MPS Project -- Feature Engineering"
author: "Sung-Woo Ahn Wanwen Gu Yvonne Liu Xinyue Chen"
date: "March 15, 2019"
output: 
  html_document:
    highlight: pygments
    theme: cosmo
---

<style type="text/css">

body{ /* Normal  */
      font-size: 18px;
  }

</style>

Create a matrix with one row for every device_id. Created 66 different features:

- Count of how many unique events occurred in the AM and in the PM (2 predictors total)
- Count of how many unique events occurred in each of the days between April 30 - May 8 (9 predictors total, for each day)
- Count of how many unique events occurred on weekdays and on weekends (2 predictors total)
- Count of number of events in total (1 predictor total)
- Count of how many unique apps were used in each app category (24 predictors total, for each category)
- Average longitude and latitude (2 predictors total)
- Count of unique apps used (1 predictor total)
- Categorical variable for device model and phone brand (2 predictors)
- In each app category, ratio of the count of the number of is_active occurrences to number of unique apps used in that app category (23 predictors total)

For each App Category $i$:
$$\frac{\text{# of is_active occurrences}}{\text{# of unique apps used}}$$

## Import dataset
```{r warning=FALSE, message=FALSE, error=FALSE}
library(knitr)
library(readr)
library(data.table)
library(bit64)
library(Rmpfr)
library(tidyverse)
library(kableExtra)
library(readxl)
library(chron)
library(VIM)
```
```{r}
versions<-sessionInfo()
versions
```
```{r echo=FALSE}
options(kableExtra.latex.load_packages = FALSE)
knit_hooks$set(document = function(x) {
  sub('\\usepackage[]{color}', '\\usepackage[]{xcolor}', x, fixed = TRUE)
})

```

```{r}
train <- fread("train.csv", header = T, integer64 = "character", na.strings = "NA")
setDT(train[,-1])
labelsdat <- fread("labelsdat.csv", header = T, integer64 = "character", na.strings = "NA")
uniquelabels <- fread("uniquelabels.csv", header = T, integer64 = "character", na.strings = "NA")
labeltrain <- fread("labeltrain.csv", header = T, integer64 = "character", na.strings = "NA")
gender_age <- fread("gender_age_train.csv", header = T, integer64 = "character", na.strings = "NA")
```

Is active ratio for each app category
- Instead of doing counts of is_active occurrences in each app category, we did a ratio. The ratio can be interpretted as, for every app used, how many is_active occurrences were there? By doing a ratio, we can provide more context to the is_active numbers. For example, if a device had 100 is_active occurrences, we might think that is a lot. But if these occurrences were spread out between 100 apps, then maybe it is not that much. By making this predictor a ratio, more information can be obtained.
```{r}
# Subset of the training data
response <- train[, list(device_id, event_id, app_id, is_active)]

# Vector of all unique device_ids
deviceid <- unique(train$device_id)

# Merge response with uniquelables
isactivecats <- merge(x = response, y = uniquelabels, by = 'app_id', all.x = T, allow.cartesian = T)
isactivecats <- isactivecats[order(device_id)]

# Only keep observations with is_active=1, count number of is_active occurrences in each category
sum.isactive.bycat <- isactivecats %>%
  filter(is_active == 1) %>%
  group_by(device_id, category, is_active) %>%
  dplyr::summarise(isactive.count = n())

# Count the number of apps used in each category
sum.apps.bycat <- isactivecats %>%
  filter(is_active == 1) %>%
  group_by(device_id, category, app_id) %>%
  distinct(app_id, .keep_all = T) %>%
  #dplyr::summarise(count = n()) %>%
  group_by(device_id, category) %>%
  dplyr::summarise(count = n())

sum.isactive.bycat$appcount <- sum.apps.bycat$count
```

```{r results='asis', echo=FALSE}
kable(sum.isactive.bycat[1:15,4:5], caption = 'App count vs. Is_Active Count') %>%
  kable_styling(bootstrap_options = c("striped", "bordered", "responsive", "condensed"), full_width = F)
```

```{r}
# Calculate the ratios
sum.isactive.bycat <- sum.isactive.bycat %>%
  mutate(ratio = isactive.count/appcount)

feature <- sum.isactive.bycat %>%
  select(-one_of("is_active", "isactive.count", "appcount")) %>%
  spread(key = category, value = ratio)

feature[is.na(feature)]=0

# Some device_ids not in the final table: these devices had no is_active cases
missing <- setdiff(deviceid, feature$device_id)
nas <- matrix(nrow = 394, ncol = 23)
missingdata <- cbind(missing, nas)
colnames(missingdata) <- colnames(feature)
feature <- rbind.data.frame(feature, missingdata)
```

Location, event count, app count
```{r}
test<-train
test$longitude[test$longitude==0 | test$longitude==1]<-NA
test$latitude[test$latitude==0 | test$latitude==1]<-NA

test1<-test %>%
select(device_id, longitude, latitude, event_id) %>%
group_by(device_id) %>%
dplyr::summarise(longitude=mean(longitude, na.rm=TRUE), latitude=mean(latitude, na.rm=TRUE), count_event=n_distinct(event_id))

require(data.table)
setDT(test1)
setDT(labeltrain)

labeltest<-labeltrain %>%
group_by(device_id) %>%
dplyr::summarise(n_distinct(app_id))

require(data.table)
setDT(labeltest)

m <- merge(x = labeltest, y = test1, by = 'device_id', all.x = T)
```

Count for AM/PM, Weekend/Weekday, April 30 - May 8
```{r}
# take a subset of the training data 
# containing information of event_id, device_id and timestamp
train2 <- train[, list(event_id, device_id, timestamp)]

# checking whether each event_id has a timestamp
sum(is.na(train$event_id) & !is.na(train$timestamp))    # 0
sum(!is.na(train$event_id) & is.na(train$timestamp))    # 0

# get rid of the NA values
train2 <- train2[!is.na(train2$event_id)]     # 12896417 rows (original 12896749 rows)

# separate date and time
timesplit <- unlist(strsplit(train2$timestamp, ' '))
len <- length(timesplit)
date.index <- seq(1, len-1, by=2)
time.index <- seq(2, len, by=2)
date <- timesplit[date.index]
time <- timesplit[time.index]
train2 <- cbind(train2,date,time)



# check how many unique dates in the dataset
date.unique <- unique(train2$date)
print(date.unique)
# change the two values to follow time order
temp <- date.unique[1]
date.unique[1] <- date.unique[2]
date.unique[2] <- temp

# count number of unique event_id per device_id in a specific date
# count is a list with each element being a two-column data frame
# storing the device id and its number of unique events on a specific date 
# from 2016-04-30 to 2016-05-08
count <- list()
date.unique <- unique(train2$date)
for (i in 1:length(date.unique)){
  temp <- train2[train2$date==date.unique[i]]
  setDT(temp)[, count := uniqueN(event_id), by = device_id]
  count[[i]] <- unique(temp[,list(device_id,count)])
  names(count[[i]])[2] <- date.unique[i]
}




# merge the 9 tables to form a single table of counts
merged <- count %>% reduce(full_join, by = "device_id")
# replace NA values with 0
merged[is.na(merged)] <- 0

# check whether merge retrieve back all device id
length(unique(train2$device_id))   # 23309 
dim(merged)   # 23309 rows



# count number of events based on weekday/weekend
# weekend: 2016-04-30(Sat) 2016-05-01(Sun) 2016-05-07(Sat) 2016-05-08(Sun)
# weekday: 2016-05-02(Mon) 2016-05-03(Tue) 2016-05-04(Wed) 2016-05-05(Thu) 2016-05-06(Fri)
weekend <- apply(merged[,c(2,3,9,10)], 1, sum)
weekday <- apply(merged[,4:8], 1, sum)

# append these two columns to merged dataset
date.count <- cbind(merged, weekend, weekday)




# the time column is in character type, change it to time datatype
temp.time <- chron(times=train2$time)   # note this will take a while
time.hour <- hours(temp.time)

# count number of unique events for each device in each timechunk of 4 hours
count.timechunk <- list()
count.name <- c('count.0_4','count.4_8','count.8_12','count.12_16','count.16_20','count.20_24')
for (i in 1:6){
  temp <- train2[time.hour < i*4 & time.hour >= (i-1)*4,]
  setDT(temp)[, count := uniqueN(event_id), by = device_id]
  count.timechunk[[i]] <- unique(temp[,list(device_id,count)])
  names(count.timechunk[[i]])[2] <- count.name[i]
}

# merge the 6 tables to form a single table of counts
time.count <- count.timechunk %>% reduce(full_join, by = "device_id")
# replace NA values with 0
time.count[is.na(time.count)] <- 0

# check whether merge retrieve back all device id
length(unique(train2$device_id))   # 23309 
dim(time.count)   # 23309 rows

# merge date.count and time.count
timestamp.count <- list(date.count,time.count) %>% reduce(full_join, by = "device_id")
dim(timestamp.count)    # 23309 * 18
```

App Category count
```{r}
category_feature <- data.frame(xtabs(~device_id + category, data = labeltrain)) %>%
  spread(category, Freq)
```

Create the final matrix by merging all the features
```{r}
finaltable <- list(m, category_feature, timestamp.count, feature) %>% reduce(full_join, by = "device_id")
finaltable <- merge(x = finaltable, y = gender_age[,list(device_id, group)], by = "device_id", all.x = T)
brandmodel <- train[,list(device_id, phone_brand, device_model)]
finaltable <- merge(x = finaltable, y = unique(brandmodel), by = "device_id")
finaltable$group <- as.factor(finaltable$group)
```

```{r}
str(finaltable)
head(finaltable, n = 25)
summary(finaltable$group)
```
.x categories are for app category counts and .y categories are for the is_active ratios.

## Training Validation split
```{r}
set.seed(1)
sample <- sample.int(n=nrow(finaltable), size = floor(.8*nrow(finaltable)), replace = F)
validation <- finaltable[-sample,]
training <- finaltable[sample,]
```

```{r}
fwrite(validation, "validation.csv")
fwrite(training, "training.csv")
```

## Number of Missing/0 Values in training set
```{r}
training<-fread("training.csv", header=T, integer64 = "character")
validation <- fread("validation.csv", header=T, integer64 = "character")
```
```{r}
missing.values <- map(training, ~sum(is.na(.x)))
zero.values<- map(training, ~(length(.x[which(.x==0)])))

allmissing <- cbind(missing.values, zero.values)
allmissing
```

The large number of missing and zero values could pose problems in our analysis. Some predictors could be deleted to prevent multicollinearity; like weekend/weekday.

## Why the number of NA is different
From the missing table above, we know there are 268 missing observations for the date features. Check that the 268 observations are the same devices across these 9 features.
```{r}
# Check that they are the same 268 observations
d01<-training[which(is.na(training$`2016-05-01`)),]
d02 <- training[which(is.na(training$`2016-04-30`)),]

setdiff(d01,d02)
setdiff(d02,d01)
```
just comparing 2 of the 9 features, the 268 observations match.

Look up the device_ids with NA values in the train dataset to see why they became missing.
```{r}
datemissing<-train[device_id%in%d01$device_id]
head(datemissing)
```
Looking at the table, we can see that these devices have no recorded events. Without events, there can't be any data of dates an event occurred. For these devices the date features are all set to NA.

Do the same process for app category features and is_active ratio features.
```{r}
appcat1 <- training[which(is.na(training$beauty.x)),]
appcat2 <- training[which(is.na(training$business.x)),]
setdiff(appcat1,appcat2)
setdiff(appcat2,appcat1)
appcatmissing <- train[device_id%in%appcat1$device_id]
length(unique(appcatmissing$device_id))
appcatmissing[268:280,]
```
In addition to the 268 devices that had no recorded events, the devices that had events but no corresponding app_ids recorded will also be set to NA.

```{r}
isactive1 <- training[which(is.na(training$beauty.y)),]
isactive2 <- training[which(is.na(training$business.y)),]
setdiff(isactive1,isactive2)
setdiff(isactive2,isactive1)
isactivemissing <- train[device_id%in%isactive1$device_id]
length(unique(isactivemissing$device_id))
isactivemissing[961:975,]
```
In addition to those devices that either had no recorded events, or those that had events but no recored app activity, the is_active ratio will also consider as NA those devices that have events and recorded app activity but never had an instance where is_active equalled to 1.




## Remove the 318 Observations with NA values

NA values can be problematic for model building so remove them.
```{r}
training.NoNA<- training[is.na(training$entertainment.y)==FALSE]
validation.NoNA<-validation[which(is.na(validation$entertainment.y)==FALSE)]
fwrite(training.NoNA, "training_NoNA.csv")
fwrite(validation.NoNA, "validation_NoNA.csv")
```
```{r}
training.NoNA <- fread("training_NoNA.csv", header = T, integer64 = "character")
validation.NoNA <- fread("validation_NoNA.csv", header = T, integer64 = "character")
```

## Remove multicollinearity

Removed:

- Weekend (correlated with Weekday)
- Count.0_4 (correlated with the rest of the time chunks)
- 2016-05-08 (correlated with the rest of the other dates)
- beauty.x (correlated with the rest of the app usage count features)
- beauty.y (correlated with the rest of the is_active ratio features)

Other candidates:

- count_event (This is a sum of the event counts: summing up weekend.weekday or AM/PM will give count_event)
  - However, deleting Weekend and Morning may resolve this multicollinearity
- n_distinct(app_id) (This is a sum of unique app usage count in each app category)
  - However, deleting one feature from the app usage counts may resolve this multicollinearity

```{r}
# For training
training.NoNA.NoMultc <- training.NoNA %>%
# Delete one of weekend/weekday
  select(-one_of("weekend")) %>%
# Delete one of morning/afternoon
  select(-one_of("count.0_4")) %>%
# Delete one date
  select(-one_of("2016-05-08")) %>%
# Delete one app category count
  select(-one_of("beauty.x")) %>%
# Delete one is_active ratio
  select(-one_of("beauty.y"))
# Delete total event count
  #select(-one_of("count_event")) %>%
# Delete total app count
  #select(-one_of("n_distinct(app_id)"))

# For validation
validation.NoNA.NoMultc <- validation.NoNA %>%
# Delete one of weekend/weekday
  select(-one_of("weekend")) %>%
# Delete one of morning/afternoon
  select(-one_of("count.0_4")) %>%
# Delete one date
  select(-one_of("2016-05-08")) %>%
# Delete one app category count
  select(-one_of("beauty.x")) %>%
# Delete one is_active ratio
  select(-one_of("beauty.y"))
# Delete total event count
  #select(-one_of("count_event")) %>%
# Delete total app count
  #select(-one_of("n_distinct(app_id)"))
```

```{r}
# Column names cause issues with some of the models
colnames(training.NoNA.NoMultc)[2] <- 'count.app'
colnames(training.NoNA.NoMultc)[29] <- 'May01'
colnames(training.NoNA.NoMultc)[30] <- 'Apr30'
colnames(training.NoNA.NoMultc)[31] <- 'May02'
colnames(training.NoNA.NoMultc)[32] <- 'May03'
colnames(training.NoNA.NoMultc)[33] <- 'May04'
colnames(training.NoNA.NoMultc)[34] <- 'May05'
colnames(training.NoNA.NoMultc)[35] <- 'May06'
colnames(training.NoNA.NoMultc)[36] <- 'May07'


colnames(validation.NoNA.NoMultc)[2] <- 'count.app'
colnames(validation.NoNA.NoMultc)[29] <- 'May01'
colnames(validation.NoNA.NoMultc)[30] <- 'Apr30'
colnames(validation.NoNA.NoMultc)[31] <- 'May02'
colnames(validation.NoNA.NoMultc)[32] <- 'May03'
colnames(validation.NoNA.NoMultc)[33] <- 'May04'
colnames(validation.NoNA.NoMultc)[34] <- 'May05'
colnames(validation.NoNA.NoMultc)[35] <- 'May06'
colnames(validation.NoNA.NoMultc)[36] <- 'May07'
```

Rearrange the features in to a logical ordering
```{r}
# Place the response column at the beginning, rearrange the date features in chronological order, place overall count features together, put app count and isactive count features together
training.NoNA.NoMultc <- training.NoNA.NoMultc[,c(1,65,3,4,5,2,6:28,43:64,30,29,31:42,66,67)]

validation.NoNA.NoMultc <- validation.NoNA.NoMultc[,c(1,65,3,4,5,2,6:28,43:64,30,29,31:42,66,67)]
```

Rename the suffixes .x and .y
```{r}
# Rename the suffix for app count features
appcounts_training <- names(training.NoNA.NoMultc[,c(7:29)])
appcounts_valid <- names(validation.NoNA.NoMultc[,c(7:29)])
for (i in 1:length(appcounts_training)) {
  appcounts_training[i] <- paste(str_split(appcounts_training[i], '\\.')[[1]][1],'appCt', sep = '.')
  appcounts_valid[i] <- paste(str_split(appcounts_valid[i], '\\.')[[1]][1],'appCt', sep = '.')
}

names(training.NoNA.NoMultc)[c(7:29)] <- appcounts_training
names(validation.NoNA.NoMultc)[c(7:29)] <- appcounts_valid

# Rename the suffix for is_active ratio features
isactiveRatios_training <- names(training.NoNA.NoMultc[,c(30:51)])
isactiveRatios_valid <- names(validation.NoNA.NoMultc[,c(30:51)])
for (i in 1:length(isactiveRatios_training)) {
  isactiveRatios_training[i] <- paste(str_split(isactiveRatios_training[i], '\\.')[[1]][1],'isactiveRat', sep = '.')
  isactiveRatios_valid[i] <- paste(str_split(isactiveRatios_valid[i], '\\.')[[1]][1],'isactiveRat', sep = '.')
}

names(training.NoNA.NoMultc)[c(30:51)]  <- isactiveRatios_training
names(validation.NoNA.NoMultc)[c(30:51)] <- isactiveRatios_valid
```

Test that everything has worked properly
```{r}
# Check the column names match between training and validation
length(names(training.NoNA.NoMultc))
length(names(validation.NoNA.NoMultc))
NoNANoMultc_match <- cbind(names(training.NoNA.NoMultc), names(validation.NoNA.NoMultc))
NoNANoMultc_match
```

Save the new datasets
```{r}
fwrite(training.NoNA.NoMultc, "training_NoNA_NoMultc.csv")
fwrite(validation.NoNA.NoMultc, "validation_NoNA_NoMultc.csv")
```

## try KNN to impute missing location value
```{r}
# training
training.NoNA.NoMultc <- fread( "training_NoNA_NoMultc.csv", integer64 = 'character')
validation.NoNA.NoMultc <- fread( "validation_NoNA_NoMultc.csv", integer64 = 'character')
knn_3 <- kNN(training.NoNA.NoMultc,variable=c("longitude","latitude"),k=5) #k=5

# validation
knn_3_val <- kNN(validation.NoNA.NoMultc,variable=c("longitude","latitude"),k=5)
```
```{r}
summary(knn_3) #no missing value in longitude and altitude
fwrite(knn_3, 'knn_3.csv')
fwrite(knn_3_val, 'knn_3_val.csv')
```


## PCA Analysis
```{r}
training <- fread("training_NoNA_NoMultc.csv", header = T, integer64 = "character")
count.train <- subset(training, select = book.appcnt:vehicle.appcnt)
ratio.train <- subset(training, select = book.isactiveCnt:vehicle.isactiveCnt)
```


```{r}
# conduct PCA on the two datasets
count.pca <- prcomp(count.train[,-1], center = TRUE, scale. = TRUE)
summary(count.pca)   # 9 PCs for cumulative proportion of >90% 
ratio.pca <- prcomp(ratio.train[,-1], center = TRUE, scale. = TRUE) 
summary(ratio.pca)   # 13 PCs for cumulative proportion of >90% 

count.train.pca <- data.frame(device_id = training$device_id, count.pca$x[,1:9], stringsAsFactors = F)
ratio.train.pca <- data.frame(device_id = training$device_id, ratio.pca$x[,1:13], stringsAsFactors = F)
```

```{r}
fwrite(count.train.pca, 'count_train_pca.csv')
fwrite(ratio.train.pca, 'ratio_train_pca.csv')
```


```{r}
# test 
validation <- fread("validation_NoNA_NoMultc.csv", header = T, integer64 = "character")
count.test <- subset(validation, select = book.x:vehicle.x)
ratio.test <- subset(validation, select = book.y:vehicle.y)
```


```{r}
count.test.pca <- predict(count.pca, newdata = count.test[,-1])
count.test.pca <- data.frame(device_id = validation$device_id, count.test.pca[,1:9], stringsAsFactors = F)
ratio.test.pca <- predict(ratio.pca, newdata = ratio.test[,-1])
ratio.test.pca <- data.frame(device_id = validation$device_id, ratio.test.pca[,1:13], stringsAsFactors = F)
```


# Replace the imputed location predictors with the imputed ones and the app category predictors with the Principal Components
```{r}
fwrite(count.test.pca, 'count_test_pca.csv')
fwrite(ratio.test.pca, 'ratio_test_pca.csv')
knn_3 <- fread('knn_3.csv', header=T, integer64 = 'character')
knn_3_val <- fread('knn_3_val.csv', header=T, integer64 = 'character')
```

```{r}
#training
training.final <- training.NoNA.NoMultc[,-c(6:28)]
training.final <- training.final[,-c(20:41)]
training.final <- training.final[,-c(3:4)]

colnames(count.train.pca) <- paste('count',colnames(count.train.pca),sep='.')
colnames(ratio.train.pca) <- paste('ratio',colnames(ratio.train.pca),sep='.')

training.final <- cbind(training.final, count.train.pca[,-1])
training.final <- cbind(training.final, ratio.train.pca[,-1])
training.final[order(device_id)]
knn_3[order(device_id)]
training.final <- cbind(training.final, knn_3[,3:4])
fwrite(training.final, 'training_final.csv')


# validation
validation.final <- validation.NoNA.NoMultc[,-c(6:28)]
validation.final <- validation.final[,-c(20:41)]
validation.final <- validation.final[,-c(3:4)]

colnames(count.test.pca) <- paste('count',colnames(count.test.pca),sep='.')
colnames(ratio.test.pca) <- paste('ratio',colnames(ratio.test.pca),sep='.')

validation.final <- cbind(validation.final, count.test.pca[,-1])
validation.final <- cbind(validation.final, ratio.test.pca[,-1])
validation.final[order(device_id)]
knn_3_val<-setDT(knn_3_val)[order(device_id)]
validation.final <- cbind(validation.final, knn_3_val[,3:4])
fwrite(validation.final, 'validation_final.csv')
```

```{r}
# Column names cause issues with some of the models
colnames(train.final)[2] <- 'count.app'
colnames(train.final)[4] <- 'May01'
colnames(train.final)[5] <- 'Apr30'
colnames(train.final)[6] <- 'May02'
colnames(train.final)[7] <- 'May03'
colnames(train.final)[8] <- 'May04'
colnames(train.final)[9] <- 'May05'
colnames(train.final)[10] <- 'May06'
colnames(train.final)[11] <- 'May07'


colnames(valid.final)[2] <- 'count.app'
colnames(valid.final)[4] <- 'May01'
colnames(valid.final)[5] <- 'Apr30'
colnames(valid.final)[6] <- 'May02'
colnames(valid.final)[7] <- 'May03'
colnames(valid.final)[8] <- 'May04'
colnames(valid.final)[9] <- 'May05'
colnames(valid.final)[10] <- 'May06'
colnames(valid.final)[11] <- 'May07'

train.final <- train.final[,c(1,18,43,44,3,2,21:29,30:42,5,4,6:17,19,20)]
valid.final <- valid.final[,c(1,18,43,44,3,2,21:29,30:42,5,4,6:17,19,20)]
```

Check that everything has worked properly
```{r}
length(names(train.final))
length(names(valid.final))
final_match <- cbind(names(train.final), names(valid.final))
final_match
```

Save the new datasets
```{r}
fwrite(train.final, "training_final.csv")
fwrite(valid.final, "validation_final.csv")
```

#change category.count into category.indicator 
```{r}
indicator_train <- fread('training_NoNA_NoMultc.csv',header=T,integer64='character')
indicator_train[,7:29] <- replace(indicator_train[,7:29],indicator_train[,7:29]>0,1)
indicator_train <- indicator_train[,c(2,7:29)]

indicator_valid <- fread('validation_NoNA_NoMultc.csv',header=T,integer64='character')
indicator_valid[,7:29] <- replace(indicator_valid[,7:29],indicator_valid[,7:29]>0,1)
indicator_valid <- indicator_valid[,c(2,7:29)]

fwrite(indicator_train, "indicator_train.csv")
fwrite(indicator_valid, "indicator_valid.csv")
```

#change 23 into 3 category:business, game, other
```{r}
category_train <- fread('training_NoNA_NoMultc.csv',header=T,integer64='character')
category_train <- category_train[,c(2,7:29)]
category_train$other.totalCt <- rowSums(category_train[,-c(1,3,10)])
category_train <- category_train[,c(1,3,10,25)]

category_valid <- fread('validation_NoNA_NoMultc.csv',header=T,integer64='character')
category_valid <- category_valid[,c(2,7:29)]
category_valid$other.totalCt <- rowSums(category_valid[,-c(1,3,10)])
category_valid <- category_valid[,c(1,3,10,25)]

fwrite(category_train, "category_train.csv")
fwrite(category_valid, "category_valid.csv")
```

