---
title: "MPS Project -- Feature Engineering"
author: "Sung-Woo Ahn Wanwen Gu Yvonne Liu Xinyue Chen"
date: "March 15, 2019"
output: 
  html_document:
    highlight: pygments
    theme: cosmo
---

<style type="text/css">

body{ /* Normal  */
      font-size: 18px;
  }

</style>

Create a matrix with one row for every device_id. Created 67 different features:

- Count of how many unique events occurred in the AM and in the PM (2 predictors total)
- Count of how many unique events occurred in each of the days between April 30 - May 8 (9 predictors total, for each day)
- Count of how many unique events occurred on weekdays and on weekends (2 predictors total)
- Count of number of events in total (1 predictor total)
- Count of how many unique apps were used in each app category (24 predictors total, for each category)
- Average longitude and latitude (2 predictors total)
- Count of unique apps used (1 predictor total)
- Categorical variable for device model and phone brand (2 predictors)
- In each app category ratio of the count of the nmber of is_active events to number of unique apps used in each app category (23 predictors total)

For each App Category $i$:
$$\frac{\text{# of is_active occurrences}}{\text{# of unique apps used}}$$

## Import dataset
```{r warning=FALSE, message=FALSE, echo=FALSE}
library(knitr)
library(readr)
library(data.table)
library(bit64)
library(Rmpfr)
library(tidyverse)
library(kableExtra)
library(readxl)
library(chron)

```
```{r echo=FALSE}
options(kableExtra.latex.load_packages = FALSE)
knit_hooks$set(document = function(x) {
  sub('\\usepackage[]{color}', '\\usepackage[]{xcolor}', x, fixed = TRUE)
})

```

```{r}
train <- fread("train.csv", header = T, integer64 = "character", na.strings = "NA")
setDT(train[,-1])
labelsdat <- fread("labelsdat.csv", header = T, integer64 = "character", na.strings = "NA")
uniquelabels <- fread("uniquelabels.csv", header = T, integer64 = "character", na.strings = "NA")
labeltrain <- fread("labeltrain.csv", header = T, integer64 = "character", na.strings = "NA")
gender_age <- fread("gender_age_train.csv", header = T, integer64 = "character", na.strings = "NA")
```

Is active ratio for each app category
```{r}
# Subset of the training data
response <- train[, list(device_id, event_id, app_id, is_active)]

# In the labelsdat dataset, for each app_id delete repeat categories
#uniquelabels <- labelsdat %>%
#  arrange(app_id) %>%
#  group_by(app_id, category) %>%
#  distinct(category, .keep_all = T)

# Vector of all unique device_ids
deviceid <- unique(train$device_id)

# Merge response with uniquelables
isactivecats <- merge(x = response, y = uniquelabels, by = 'app_id', all.x = T, allow.cartesian = T)
isactivecats <- isactivecats[order(device_id)]
```


```{r}
# Only keep observations with is_active=1, count number of is_active in each category
sum.isactive.bycat <- isactivecats %>%
  filter(is_active == 1) %>%
  group_by(device_id, category, is_active) %>%
  dplyr::summarise(count = n())

# Count the number of apps used in each category
sum.apps.bycat <- isactivecats %>%
  filter(is_active == 1) %>%
  group_by(device_id, category, app_id) %>%
  distinct(app_id, .keep_all = T) %>%
  dplyr::summarise(count = n()) %>%
  group_by(device_id, category) %>%
  dplyr::summarise(count = n())

# Calculate the ratios
sum.isactive.bycat$appcount <- sum.apps.bycat$count
sum.isactive.bycat <- sum.isactive.bycat %>%
  mutate(ratio = count/appcount)

feature <- sum.isactive.bycat %>%
  select(-one_of("is_active", "count", "appcount")) %>%
  spread(key = category, value = ratio)

feature[is.na(feature)]=0

# Some device_ids not in the final table: these devices had no is_active cases
missing <- setdiff(deviceid, feature$device_id)
nas <- matrix(nrow = 394, ncol = 23)
missingdata <- cbind(missing, nas)
colnames(missingdata) <- colnames(feature)
feature <- rbind.data.frame(feature, missingdata)
```

Location, event count, app count
```{r}
test<-train
test$longitude[test$longitude==0 | test$longitude==1]<-NA
test$latitude[test$latitude==0 | test$latitude==1]<-NA

test1<-test %>%
select(device_id, longitude, latitude, event_id) %>%
group_by(device_id) %>%
dplyr::summarise(longitude=mean(longitude, na.rm=TRUE), latitude=mean(latitude, na.rm=TRUE), count_event=n_distinct(event_id))

require(data.table)
setDT(test1)
setDT(labeltrain)

labeltest<-labeltrain %>%
group_by(device_id) %>%
dplyr::summarise(n_distinct(app_id))

require(data.table)
setDT(labeltest)

m <- merge(x = labeltest, y = test1, by = 'device_id', all.x = T)
```

```{r}
# take a subset of the training data 
# containing information of event_id, device_id and timestamp
train2 <- train[, list(event_id, device_id, timestamp)]

# checking whether each event_id has a timestamp
sum(is.na(train$event_id) & !is.na(train$timestamp))    # 0
sum(!is.na(train$event_id) & is.na(train$timestamp))    # 0

# get rid of the NA values
train2 <- train2[!is.na(train2$event_id)]     # 12896417 rows (original 12896749 rows)

# separate date and time
timesplit <- unlist(strsplit(train2$timestamp, ' '))
len <- length(timesplit)
date.index <- seq(1, len-1, by=2)
time.index <- seq(2, len, by=2)
date <- timesplit[date.index]
time <- timesplit[time.index]
train2 <- cbind(train2,date,time)



# check how many unique dates in the dataset
date.unique <- unique(train2$date)
print(date.unique)
# change the two values to follow time order
temp <- date.unique[1]
date.unique[1] <- date.unique[2]
date.unique[2] <- temp

# count number of unique event_id per device_id in a specific date
# count is a list with each element being a two-column data frame
# storing the device id and its number of unique events on a specific date 
# from 2016-04-30 to 2016-05-08
count <- list()
date.unique <- unique(train2$date)
for (i in 1:length(date.unique)){
  temp <- train2[train2$date==date.unique[i]]
  setDT(temp)[, count := uniqueN(event_id), by = device_id]
  count[[i]] <- unique(temp[,list(device_id,count)])
  names(count[[i]])[2] <- date.unique[i]
}




# merge the 9 tables to form a single table of counts
merged <- count %>% reduce(full_join, by = "device_id")
# replace NA values with 0
merged[is.na(merged)] <- 0

# check whether merge retrieve back all device id
length(unique(train2$device_id))   # 23309 
dim(merged)   # 23309 rows



# count number of events based on weekday/weekend
# weekend: 2016-04-30(Sat) 2016-05-01(Sun) 2016-05-07(Sat) 2016-05-08(Sun)
# weekday: 2016-05-02(Mon) 2016-05-03(Tue) 2016-05-04(Wed) 2016-05-05(Thu) 2016-05-06(Fri)
weekend <- apply(merged[,c(2,3,9,10)], 1, sum)
weekday <- apply(merged[,4:8], 1, sum)

# append these two columns to merged dataset
date.count <- cbind(merged, weekend, weekday)




# the time column is in character type, change it to time datatype
temp.time <- chron(times=train2$time)   # note this will take a while
time.hour <- hours(temp.time)

# separate train2 dataset according to morning/afternoon 
morning.data <- train2[time.hour < 12,]
afternoon.data <- train2[time.hour >= 12,]
# count events per device
setDT(morning.data)[, count := uniqueN(event_id), by = device_id]
setDT(afternoon.data)[, count := uniqueN(event_id), by = device_id]
names(morning.data)[6] <- 'morning'
names(afternoon.data)[6] <- 'afternoon'
morning.count <- unique(morning.data[,list(device_id,morning)])
afternoon.count <- unique(afternoon.data[,list(device_id,afternoon)])

# merge the 2 tables to form a single table of counts
time.count <- list(morning.count,afternoon.count) %>% reduce(full_join, by = "device_id")
# replace NA values with 0
time.count[is.na(time.count)] <- 0


# check whether merge retrieve back all device id
length(unique(train2$device_id))   # 23309 
dim(time.count)   # 23309 rows




# merge date.count and time.count
timestamp.count <- list(date.count,time.count) %>% reduce(full_join, by = "device_id")
dim(timestamp.count)    # 23309    14
```

App Category count
```{r}
category_feature <- data.frame(xtabs(~device_id + category, data = labeltrain)) %>%
  spread(category, Freq)
```

```{r}
finaltable <- list(m, category_feature, timestamp.count, feature) %>% reduce(full_join, by = "device_id")
finaltable <- merge(x = finaltable, y = gender_age[,list(device_id, group)], by = "device_id", all.x = T)
brandmodel <- train[,list(device_id, phone_brand, device_model)]
finaltable <- merge(x = finaltable, y = unique(brandmodel), by = "device_id")
finaltable$group <- as.factor(finaltable$group)
```

```{r}
table1 <- merge(x = m, y = category_feature, by = "device_id", all.x = T, all.y = T)
table2 <- merge(x = table1, y = timestamp.count, by = "device_id", all.x = T, all.y = T)
table3 <- merge(x = table2, y = feature, by = "device_id", all.x = T, all.y = T)

```


## Validation
```{r}
set.seed(1)
sample <- sample.int(n=nrow(finaltable), size = floor(.8*nrow(finaltable)), replace = F)
validation <- finaltable[-sample,]
training <- finaltable[sample,]
```

```{r}
fwrite(validation, "validation.csv")
fwrite(training, "training.csv")
```

```{r}
train.impute <- rfImpute(group~. , data=training)
train.rf <- randomForest(group~. , data=training)
len = dim(training)[2]
for (i in 1:length(len)){
  print(class(training[,i]))
}
model1 <- randomForest(group ~ ., data = training, importance = TRUE, na.action = na.omit)
```