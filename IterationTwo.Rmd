---
title: "MPS Project -- Iteration 2"
author: "Sung-Woo Ahn Wanwen Gu Yvonne Liu Xinyue Chen"
date: "April 5, 2019"
output: 
  html_document:
    highlight: pygments
    theme: cosmo
---

<style type="text/css">

body{ /* Normal  */
      font-size: 18px;
  }

</style>



## Import dataset
```{r warning=FALSE, message=FALSE, error=FALSE}
library(knitr)
library(data.table)
library(bit64)
library(Rmpfr)
library(tidyverse)
library(kableExtra)
library(VIM)
library(DT)
library(e1071)
library(mlbench)
library(corrplot)
library(bnlearn)
library(gridExtra)
library(plotly)
library(MLmetrics)
library(nnet)
library(randomForest)
```
```{r}
versions<-sessionInfo()
versions
```
```{r echo=FALSE}
options(kableExtra.latex.load_packages = FALSE)
knit_hooks$set(document = function(x) {
  sub('\\usepackage[]{color}', '\\usepackage[]{xcolor}', x, fixed = TRUE)
})

```


```{r}
train.final<-fread('training_final.csv', header=T, integer64='character')
valid.final<-fread('validation_final.csv',header=T, integer64='character')
train.NoNANoM<-fread('training_NoNA_NoMultc.csv', header = T, integer64 = 'character')
valid.NoNANoM<-fread('validation_NoNA_NoMultc.csv', header = T, integer64 = 'character')

names(train.NoNANoM)[24] <- "socialnetworking.appCt"
names(train.NoNANoM)[46] <- "socialnetworking.isactiveRat"
names(valid.NoNANoM)[24] <- "socialnetworking.appCt"
names(valid.NoNANoM)[46] <- "socialnetworking.isactiveRat"

fwrite(train.NoNANoM, 'training_NoNA_NoMultc.csv', na="NA")
fwrite(valid.NoNANoM, 'validation_NoNA_NoMultc.csv', na="NA")



#match two datasets
# valid.final<-valid.final[,-4]
# train.final<-train.final[, -11]
```

## Baseline -- All the count features
### Naive Bayes
```{r}
traintotal <- cbind(train.NoNANoM[,-c(1,3,4,66,67)], train.final[,c(3,4)])
validtotal <- cbind(valid.NoNANoM[,-c(1,3,4,66,67)], valid.final[,c(3,4)])
traintotal$group <- as.factor(traintotal$group)
validtotal$group <- as.factor(validtotal$group)

fitnb<-naiveBayes(group~., data=traintotal)
prednb<-predict(fitnb, validtotal)
summary(prednb)
mean(prednb!=validtotal$group)

#log-loss
prednbprobs <-predict(fitnb, validtotal, type = 'raw')
prednbprobsdat <- data.frame(validtotal$group, prednbprobs)
logloss <- vector(length = length(prednbprobsdat$validtotal.group))
for (i in 1:length(prednbprobsdat$validtotal.group)) {
  clas=grep(str_split(paste(prednbprobsdat$validtotal.group[i]), '-')[[1]][1], names(prednbprobsdat))
  logloss[i] = log(prednbprobsdat[i,clas])
}
-mean(logloss)
-mean(logloss[is.infinite(logloss)==FALSE])

MultiLogLoss(y_pred = prednbprobs, y_true = validtotal$group)
```

### RF
```{r}
set.seed(1223)
fit.rf <- randomForest(as.factor(group)~., data = traintotal, na.action = na.omit)

rf.pred <- predict(fit.rf, newdata=validtotal)
table(rf.pred, validtotal$group)
mean(rf.pred[is.na(rf.pred)==FALSE]!=validtotal$group[is.na(rf.pred)==FALSE])

predrfprobs <-predict(fit.rf, validtotal, type = 'prob')
predrfprobsdat <- data.frame(validtotal$group, predrfprobs)
logloss <- vector(length = length(predrfprobsdat$validtotal.group))
for (i in 1:length(predrfprobsdat$validtotal.group)) {
  clas=grep(str_split(paste(predrfprobsdat$validtotal.group[i]), '-')[[1]][1], names(predrfprobsdat))
  logloss[i] = log(predrfprobsdat[i,clas])
}
-mean(logloss[is.infinite(logloss)==FALSE])

MultiLogLoss(y_pred = predrfprobs, y_true = validtotal$group)

ginis<-importance(fit.rf)
ginis<-data.frame('gini'=ginis[,1], 'categ' = rownames(ginis))
arrange(ginis, desc(gini))
```

### SVM
```{r}
fit.svm <- svm(as.factor(group) ~ . , traintotal, probability=TRUE)
pred_svm <- predict(fit.svm, validtotal)
mean(as.character(pred_svm) != as.character(validtotal$group))
table(pred_svm, validtotal$group)

predsvmprobs <-predict(fit.svm, validtotal, probability = T)
predsvmprobs <- attr(predsvmprobs, 'probabilities')
predsvmprobsdat <- data.frame(validtotal$group, predsvmprobs)
logloss <- vector(length = length(predsvmprobsdat$validtotal.group))
for (i in 1:length(predsvmprobsdat$validtotal.group)) {
  clas=grep(str_split(paste(predsvmprobsdat$validtotal.group[i]), '-')[[1]][1], names(predsvmprobsdat))
  logloss[i] = log(predsvmprobsdat[i,clas])
}
-mean(logloss)
```

### Logistic
```{r}
train_log<- traincateg
train_log<-na.omit(train_log)
valid_log<-validcateg
valid_log<-na.omit(valid_log)

model_log <- multinom(group ~ ., data = traincateg, MaxNWts = 100000, model = TRUE, probability = TRUE)
pred_log<-predict(model_log,valid_log)
pred_log_score<-predict (model_log,valid_log, 'probs')
mean(as.character(pred_log) != as.character(valid_log$group))
table(pred_log, valid_log$group)
# coef(model_log)

predlogprobsdat <- data.frame(validcateg$group, pred_log_score)
logloss <- vector(length = length(predlogprobsdat$validcateg.group))
for (i in 1:length(predlogprobsdat$validcateg.group)) {
  clas=grep(str_split(paste(predlogprobsdat$validcateg.group[i]), '-')[[1]][1], names(predlogprobsdat))
  logloss[i] = log(predlogprobsdat[i,clas])
}
-mean(logloss)
```

### Performance
```{r results='asis'}
performancecateg <-data.frame('features' = c('App Ct categorical features','App Ct categorical features','App Ct categorical features','App Ct categorical features'), 'Model' = c('NB','RF','SVM','Logistic'), 'Logloss' = c(2.711981,2.499703,2.307586,2.300363), 'Misclass' = c( 0.8441865,0.8295723,0.8269933,0.815173))
kable(performancecateg, caption = 'Performance of App Ct Categorical Variables') %>%
  kable_styling(bootstrap_options = c("striped", "bordered", "responsive", "condensed"), full_width = F)
```





## Naive Bayes: Start with small subset of features

### Count.app, count_event, weekday, group
```{r}
#features: count.app, count_event, weekday, group
train1<-cbind(train.final[,6], train.final[,5], train.final[,37], train.final[,2])
valid1<-cbind(valid.final[,6], valid.final[,5], valid.final[,37], valid.final[,2])
fit1<-naiveBayes(as.factor(group)~., data=train1)
valid1$group<-as.factor(valid1$group)
pred1<-predict(fit1, valid1)
pred1probs<-predict(fit1, valid1, type ='raw')
summary(pred1)
# F23- F24-26 F27-28 F29-32 F33-42   F43+   M22- M23-26 M27-28 M29-31 M32-38   M39+ 
#1566      0      0      0      0      0   2136    283      9      0    428    231 
mean(pred1!=valid1$group)
#[1] 0.9024285

#log-loss
pred1probsdat <- data.frame(valid1$group, pred1probs)
logloss <- vector(length = length(pred1probsdat$valid1.group))
clas<-vector(length = length(pred1probsdat$valid1.group))
for (i in 1:length(pred1probsdat$valid1.group)) {
  clas=grep(str_split(paste(pred1probsdat$valid1.group[i]), '-|\\+')[[1]][1], names(pred1probsdat))
  logloss[i] = log(pred1probsdat[i,clas])
}
-mean(logloss)
```
```{r}
confusion1 <- as.data.frame(table(pred1, valid1$group))
p<-ggplot(confusion1, aes(Var2, pred1)) +
  geom_tile(aes(fill = Freq), colour='gray') +
  scale_fill_gradient(low='antiquewhite', high = 'purple') +
  theme(axis.text.x = element_text(angle = 80, hjust = 1, size = 9),
        axis.text.y = element_text(size = 9),
        axis.title = element_text(size = 10),
        plot.title = element_text(size = 12)) +
  labs(x= 'Observed', y= 'Predicted', title = 'Confusion Matrix')
p
```

### Count.app, count_event, weekday, group, 2016-04-30 -- 2016-05-07
```{r}
#features: count.app, count_event, weekday, group, 2016-04-30--2016-05-07
train2<-cbind(train1, train.final[, c(seq(29, 36))])
valid2<-cbind(valid1, valid.final[, c(seq(29, 36))])
fit2<-naiveBayes(as.factor(group)~., data=train2)
valid2$group<-as.factor(valid2$group)
pred2<-predict(fit2, valid2)
summary(pred2)
#F23- F24-26 F27-28 F29-32 F33-42   F43+   M22- M23-26 M27-28 M29-31 M32-38   M39+ 
#3813      0      0     35     44     74    213    105     20     46     63    240  
mean(pred2!=valid2$group)
# 0.9204814

#log-loss
pred2probs <-predict(fit2, valid2, type = 'raw')
pred2probsdat <- data.frame(valid2$group, pred2probs)
logloss <- vector(length = length(pred2probsdat$valid2.group))
for (i in 1:length(pred2probsdat$valid2.group)) {
  clas=grep(str_split(paste(pred2probsdat$valid2.group[i]), '-|\\+')[[1]][1], names(pred2probsdat))
  logloss[i] = log(pred2probsdat[i,clas])
}
-mean(logloss)
-mean(logloss[is.infinite(logloss)==FALSE])
```
Adding the date features made the classifications worse

### Count.app, count_event, weekday, group, count.4_8 -- count.20-24
```{r}
#features: count.app, count_event, weekday, group, count.4_8, count.8_12, count.12_16, count.16-20, count.20-24
train3<-cbind(train1, train.final[, c(seq(38, 42))])
valid3<-cbind(valid1, valid.final[, c(seq(38, 42))])
fit3<-naiveBayes(as.factor(group)~., data=train3)
valid3$group<-as.factor(valid3$group)
pred3<-predict(fit3, valid3)
summary(pred3)
#F23- F24-26 F27-28 F29-32 F33-42   F43+   M22- M23-26 M27-28 M29-31 M32-38   M39+ 
#78      0      2     45      8     45   3874    168     23      8    190    212 
mean(pred3!=valid3$group)
#0.9065119

#log-loss
pred3probs <-predict(fit3, valid3, type = 'raw')
pred3probsdat <- data.frame(valid3$group, pred3probs)
logloss <- vector(length = length(pred3probsdat$valid3.group))
for (i in 1:length(pred3probsdat$valid3.group)) {
  clas=grep(str_split(paste(pred3probsdat$valid3.group[i]), '-|\\+')[[1]][1], names(pred3probsdat))
  logloss[i] = log(pred3probsdat[i,clas])
}
-mean(logloss)
-mean(logloss[is.infinite(logloss)==FALSE])
```
Adding the hourly time features made the classifications worse

### Count.app, count_event, weekday, group, count.pc
```{r}
#features: count.app, count_event, weekday, group, count.pc
train4<-cbind(train1, train.final[, c(seq(20, 28))])
valid4<-cbind(valid1, valid.final[, c(seq(20, 28))])
fit4<-naiveBayes(as.factor(group)~., data=train4)
valid4$group<-as.factor(valid4$group)
pred4<-predict(fit4, valid4)
summary(pred4)
#F23- F24-26 F27-28 F29-32 F33-42   F43+   M22- M23-26 M27-28 M29-31 M32-38   M39+ 
# 118      2   3561      1    195    246      2     12     48     79     17    372  
mean(pred4!=valid4$group)
#0.9314421

#log-loss
pred4probs <-predict(fit4, valid4, type = 'raw')
pred4probsdat <- data.frame(valid4$group, pred4probs)
logloss <- vector(length = length(pred4probsdat$valid4.group))
for (i in 1:length(pred4probsdat$valid4.group)) {
  clas=grep(str_split(paste(pred4probsdat$valid4.group[i]), '-|\\+')[[1]][1], names(pred4probsdat))
  logloss[i] = log(pred4probsdat[i,clas])
}
-mean(logloss)
-mean(logloss[is.infinite(logloss)==FALSE])
```

### count.app, count_event, weekday, group, ratio.pc
```{r}
#features:  count.app, count_event, weekday, group, ratio.pc
train5<-cbind(train1, train.final[, c(seq(16, 28))])
valid5<-cbind(valid1, valid.final[, c(seq(16, 28))])
fit5<-naiveBayes(as.factor(group)~., data=train5)
valid5$group<-as.factor(valid5$group)
pred5<-predict(fit5, valid5)
summary(pred5)
# F23- F24-26 F27-28 F29-32 F33-42   F43+   M22- M23-26 M27-28 M29-31 M32-38   M39+ 
# 3189      5    618     30     14    192     69    141     44     39    207    105 
mean(pred5!=valid5$group)
# 0.9228455

#log-loss
pred5probs <-predict(fit5, valid5, type = 'raw')
pred5probsdat <- data.frame(valid5$group, pred5probs)
logloss <- vector(length = length(pred5probsdat$valid5.group))
for (i in 1:length(pred5probsdat$valid5.group)) {
  clas=grep(str_split(paste(pred5probsdat$valid5.group[i]), '-|\\+')[[1]][1], names(pred5probsdat))
  logloss[i] = log(pred5probsdat[i,clas])
}
-mean(logloss)
-mean(logloss[is.infinite(logloss)==FALSE])
```

### count.app, count_event, weekday, group, longitude, latitude
```{r}
#features: count.app, count_event, weekday, group, longitude, latitude
train6<-cbind(train1, train.final[, c(3,4)])
valid6<-cbind(valid1, valid.final[, c(3,4)])
fit6<-naiveBayes(as.factor(group)~., data=train6)
valid6$group<-as.factor(valid6$group)
pred6<-predict(fit6, valid6)
summary(pred6)
#F23- F24-26 F27-28 F29-32 F33-42   F43+   M22- M23-26 M27-28 M29-31 M32-38   M39+ 
#2770      0    154      0     40      0    437    233      9      0    839    171 
mean(pred6!=valid6$group)
# 0.8934021

#log-loss
pred6probs <-predict(fit6, valid6, type = 'raw')
pred6probsdat <- data.frame(valid6$group, pred6probs)
logloss <- vector(length = length(pred6probsdat$valid6.group))
for (i in 1:length(pred6probsdat$valid6.group)) {
  clas=grep(str_split(paste(pred6probsdat$valid6.group[i]), '-|\\+')[[1]][1], names(pred6probsdat))
  logloss[i] = log(pred6probsdat[i,clas])
}
-mean(logloss)
```
The best model is with the features count.app, count_event, weekday, group, longitude, latitude, with missclassification rate of 89.4%.

#try category.indicator
```{r}
#features: category.count
indicator_train <- fread('indicator_train.csv',header=T,integer64 = 'character')
indicator_valid <- fread('indicator_valid.csv',header=T,integer64 = 'character')
fit7<-naiveBayes(as.factor(group)~., data=indicator_train)
indicator_valid$group<-as.factor(indicator_valid$group)
pred7<-predict(fit7, indicator_valid)
summary(pred7)
#F23- F24-26 F27-28 F29-32 F33-42   F43+   M22- M23-26 M27-28 M29-31 M32-38   M39+ 
#0      4       0      0     0       2487   468    0      236    1454    4      0
mean(pred7!=indicator_valid$group)
# 0.9024285

#log-loss
pred7probs <-predict(fit7, indicator_valid, type = 'raw')
pred7probsdat <- data.frame(indicator_valid$group, pred7probs)
logloss <- vector(length = length(pred7probsdat$indicator_valid.group))
for (i in 1:length(pred7probsdat$indicator_valid.group)) {
  clas=grep(str_split(paste(pred7probsdat$indicator_valid.group[i]), '-|\\+')[[1]][1], names(pred7probsdat))
  logloss[i] = log(pred7probsdat[i,clas])
}
-mean(logloss)
# 5.883481
```

#try 3 categories: business, game, other
```{r}
#features: category.count
category_train <- fread('category_train.csv',header=T,integer64 = 'character')
category_valid <- fread('category_valid.csv',header=T,integer64 = 'character')
fit8<-naiveBayes(as.factor(group)~., data=category_train)
category_valid$group<-as.factor(category_valid$group)
pred8<-predict(fit8, category_valid)
summary(pred8)
#  F23- F24-26 F27-28 F29-32 F33-42   F43+   M22- M23-26 M27-28 M29-31 M32-38 M39+ 
# 1739      1      0      0    167     22   2267     32      0      0    184  241

mean(pred8!=category_valid$group)
# 0.9125296

#log-loss
pred8probs <-predict(fit8, category_valid, type = 'raw')
pred8probsdat <- data.frame(category_valid$group, pred7probs)
logloss <- vector(length = length(pred8probsdat$category_valid.group))
for (i in 1:length(pred8probsdat$category_valid.group)) {
  clas=grep(str_split(paste(pred8probsdat$category_valid.group[i]), '-|\\+')[[1]][1], names(pred8probsdat))
  logloss[i] = log(pred8probsdat[i,clas])
}
-mean(logloss)
# 5.883481
```
## Possible Causes of the Misclassifications

### Check the Independence Assumption
```{r fig.height=14, fig.width=14}
train.final$group <- as.factor(train.final$group)
corr <- cor(train.final[,-c(1,2,43,44)])
corrplot(corr, order = "hclust", type = 'lower', tl.col = 'black', tl.srt = 45)

corrM <- cor(train.NoNANoM[,-c(1,2,66,67)])
corrplot(corrM, type = 'lower', tl.col = 'black', tl.srt = 45)
```
We can see from these two plots that there are some significant correlations between the features. The date features are all correlated with each other.

### Check the Distributions: Are they really Normal?
```{r fig.height=10, fig.width=12}
ggplot(data = train.final, aes(x = count_event, fill = group)) +
  geom_histogram(binwidth = 10) +
  scale_fill_manual(values=c("#F44336", "#E91E63", "#9C27B0", "#673AB7", "#3F51B5", "#2196F3", "#03A9F4", "#00BCD4", "#009688", "#4CAF50", "#8BC34A", "#CDDC39")) +
  xlim(c(0,250)) +
  ggtitle("Event Count")

ggplot(data = train.final, aes(x = count.app, fill = group)) +
  geom_histogram(binwidth = 10) +
  scale_fill_manual(values=c("#F44336", "#E91E63", "#9C27B0", "#673AB7", "#3F51B5", "#2196F3", "#03A9F4", "#00BCD4", "#009688", "#4CAF50", "#8BC34A", "#CDDC39")) +
  xlim(c(0,250)) +
  ggtitle("App Count")

ggplot(data = train.final, aes(x = longitude)) +
  geom_histogram(binwidth = 10) +
  xlim(c(0,750)) +
  ggtitle("Longitude")

ggplot(data = train.final, aes(x = latitude)) +
  geom_histogram(binwidth = 10) +
  xlim(c(0,750)) +
  ggtitle("Latitude")

ggplot(data = train.final, aes(x = weekday)) +
  geom_histogram(binwidth = 10) +
  xlim(c(0,750)) +
  ggtitle("Weekday")

countPCgraphs <- map(names(train.final[,7:15]), ~ggplot(data=train.final, aes_string(x=.x))+ xlim(c(-7,7)) +
  geom_histogram(binwidth = .05))

marrangeGrob(countPCgraphs, ncol=2, nrow = 3)

ratioPCgraphs <- map(names(train.final[,16:28]), ~ggplot(data=train.final, aes_string(x=.x))+ xlim(c(-7,7)) +
  geom_histogram(binwidth = .05))

marrangeGrob(ratioPCgraphs, ncol=2, nrow = 3)
```

```{r fig.height=10, fig.width=12, warning=FALSE}
names(train.NoNANoM)[c(24,46)] <- c("socialnetworking.appct", "socialnetworking.isactiveRat")
graphs3 <- map(names(train.NoNANoM[,-c(1,2,3,4,66,67)]), ~ggplot(data=train.NoNANoM, aes_string(x=.x))+
  geom_histogram())

marrangeGrob(graphs3, ncol=2, nrow = 3)
```

- The principal components are actually Gaussian.
- The event count, app count, and weekdays are all heavily skewed. Since these are count features, we should perhaps be using the multinomial distribution instead.


$$P(F23-|features)=\frac{P(feature1|F23-)*P(feature2|F23-)*\cdots *P(feature43|F23-)*P(F23-)}{P(features)}$$

### Check between group distribution
```{r}
# Compare the predictions with the actual probabilities
pred1<-predict(fit1, valid1)
predictions1 <- data.frame(pred1, pred1probs)
predictions1 <- predictions1[,c("pred1", "M22.", "F23.", "F24.26")]

# Compare the group predictions with the feature values
valid1vars <- valid.final[,c("count.app", "count_event", "weekday")]
predictions1 <- cbind(valid1$group, predictions1, valid1vars)
```
```{r}
kable(predictions1[1:15,], caption = 'Predictions') %>%
  kable_styling(bootstrap_options = c("striped", "bordered", "responsive", "condensed"), full_width = F)
```
```{r}
# Look at the mean and sd of the gaussian distribution it is using
distrs <- cbind(fit1$tables$count.app, fit1$tables$count_event, fit1$tables$weekday)
colnames(distrs)<-c("count.appmean", "count.appsd", "count_eventmean", "count_eventsd", "weekdaymean", "weekdaysd")

# Now lot the Normal distributions
# Distribution of the App Count
caseqs <- matrix(nrow=100,ncol=12)
ecseqs <- matrix(nrow=100,ncol=12)
weseqs <- matrix(nrow=100,ncol=12)
cadists <- matrix(nrow=100,ncol=12)
ecdists <- matrix(nrow=100,ncol=12)
wedists <- matrix(nrow=100,ncol=12)

for (i in 1:12) {
  caseqs[,i]<-seq(distrs[i,1]-4*distrs[i,2],distrs[i,1]+4*distrs[i,2], length=100)
  cadists[,i]<-dnorm(caseqs[,i],mean = distrs[i,1], sd=distrs[i,2])
  
  ecseqs[,i]<-seq(distrs[i,3]-4*distrs[i,4],distrs[i,3]+4*distrs[i,4], length=100)
  ecdists[,i]<-dnorm(ecseqs[,i],mean = distrs[i,3], sd=distrs[i,4])
  
  weseqs[,i]<-seq(distrs[i,5]-4*distrs[i,6],distrs[i,5]+4*distrs[i,6], length=100)
  wedists[,i]<-dnorm(weseqs[,i],mean = distrs[i,5], sd=distrs[i,6])
}

caseqs<-c(caseqs[,1], caseqs[,2], caseqs[,3], caseqs[,4], caseqs[,5], caseqs[,6], caseqs[,7], caseqs[,8], caseqs[,9], caseqs[,10], caseqs[,11], caseqs[,12])

caseqs<- data.frame('x'=caseqs, 'group'=c(rep(fit1$levels[1], 100), rep(fit1$levels[2], 100), rep(fit1$levels[3], 100), rep(fit1$levels[4], 100), rep(fit1$levels[5], 100), rep(fit1$levels[6], 100), rep(fit1$levels[7], 100), rep(fit1$levels[8], 100), rep(fit1$levels[9], 100), rep(fit1$levels[10], 100), rep(fit1$levels[11], 100), rep(fit1$levels[12], 100)))

caseqs$y <- c(cadists[,1], cadists[,2], cadists[,3], cadists[,4], cadists[,5], cadists[,6], cadists[,7], cadists[,8], cadists[,9], cadists[,10], cadists[,11], cadists[,12])

ecseqs<-c(ecseqs[,1], ecseqs[,2], ecseqs[,3], ecseqs[,4], ecseqs[,5], ecseqs[,6], ecseqs[,7], ecseqs[,8], ecseqs[,9], ecseqs[,10], ecseqs[,11], ecseqs[,12])

ecseqs<- data.frame('x'=ecseqs, 'group'=c(rep(fit1$levels[1], 100), rep(fit1$levels[2], 100), rep(fit1$levels[3], 100), rep(fit1$levels[4], 100), rep(fit1$levels[5], 100), rep(fit1$levels[6], 100), rep(fit1$levels[7], 100), rep(fit1$levels[8], 100), rep(fit1$levels[9], 100), rep(fit1$levels[10], 100), rep(fit1$levels[11], 100), rep(fit1$levels[12], 100)))

ecseqs$y <- c(ecdists[,1], ecdists[,2], ecdists[,3], ecdists[,4], ecdists[,5], ecdists[,6], ecdists[,7], ecdists[,8], ecdists[,9], ecdists[,10], ecdists[,11], ecdists[,12])


weseqs<-c(weseqs[,1], weseqs[,2], weseqs[,3], weseqs[,4], weseqs[,5], weseqs[,6], weseqs[,7], weseqs[,8], weseqs[,9], weseqs[,10], weseqs[,11], weseqs[,12])

weseqs<- data.frame('x'=weseqs, 'group'=c(rep(fit1$levels[1], 100), rep(fit1$levels[2], 100), rep(fit1$levels[3], 100), rep(fit1$levels[4], 100), rep(fit1$levels[5], 100), rep(fit1$levels[6], 100), rep(fit1$levels[7], 100), rep(fit1$levels[8], 100), rep(fit1$levels[9], 100), rep(fit1$levels[10], 100), rep(fit1$levels[11], 100), rep(fit1$levels[12], 100)))

weseqs$y <- c(wedists[,1], wedists[,2], wedists[,3], wedists[,4], wedists[,5], wedists[,6], wedists[,7], wedists[,8], wedists[,9], wedists[,10], wedists[,11], wedists[,12])


ggplot(caseqs, aes(x=x,y=y, color=group)) +
  geom_point(position = 'jitter') +
  ggtitle('App Count')

ggplot(ecseqs, aes(x=x,y=y, color=group)) +
  geom_point(position = 'jitter') +
  ggtitle('Event Count')

ggplot(weseqs, aes(x=x,y=y, color=group)) +
  geom_point(position = 'jitter') +
  ggtitle('Weekday Count')
```


```{r fig.height=8, fig.width=7, warning=FALSE}
a<-ggplot(train.final, aes(x=group, y=count_event)) + 
  geom_jitter(position=position_jitter(0.2)) +
  ylim(c(0,1000))

b<-ggplot(train.final, aes(x=group, y=count.app)) + 
  geom_jitter(position=position_jitter(0.2))

grid.arrange(a,b, ncol=1)
```
```{r fig.height=10, fig.width=12, warning=FALSE}
graphs <- map(names(train.final[,-c(1,2,43,44)]), ~ggplot(data=train.final, aes_string(x='group', y=.x))+
  geom_jitter(position = position_jitter(.2)))

marrangeGrob(graphs, ncol=2, nrow = 3)
```


```{r fig.height=10, fig.width=12, warning=FALSE}
graphs2 <- map(names(train.NoNANoM[,-c(1,2,3,4,66,67)]), ~ggplot(data=train.NoNANoM, aes_string(x='group', y=.x))+
  geom_jitter(position = position_jitter(.2), na.rm = TRUE))

marrangeGrob(graphs2, ncol=2, nrow = 3)
```
We can see that our features are actually do not really differ between groups. The distributions are too similar to find clear classification boundaries.

```{r fig.width=10, fig.height=10}
ggplot(data = train.final) +
  geom_point(aes(x=count_event, y = count.app, color=group)) +
  xlim(c(0,800))

plot_ly(train.NoNANoM, x = ~count_event, y = ~business.appCt, z = ~weekday, color = ~group) %>%
  add_markers() %>%
  layout(scene = list(xaxis = list(title = 'count_event', range=c(0,500)),
                     yaxis = list(title = 'business.appCt', range=c(0,400)),
                     zaxis = list(title = 'weekday', range=c(0,500))))
```

## Potential Remedies

### Transformation?
```{r}
ggplot(data=train.NoNANoM, aes_string(x='group', y='business.appCt'))+
  geom_jitter(position = position_jitter(.2), na.rm = TRUE) +
  ylim(c(0,900))
```
If we zoom in onto a smaller subsection of app count, there does seem to be some variation. In the female groups, there are generally more smaller numbers, while the male groups generally seem to have higher count numbers. Naive Bayes however doesn't seem to pick this up. Maybe engineer a different feature that can pick this up. If we make these counts into categorical features, binning the counts into low, medium, and high, the Naive Bayes may be able to pick up more differences.

### Different Models Using only counts



### Try creating categorical features
#### App Counts
```{r}
# Obtain the app count features we want to bin
training <- as.data.frame(train.NoNANoM[,7:29])
# Stack the app count features into one long vector
counts <- stack(training)
# Calculate the quantiles
quantiles <- quantile(counts[,1], c(.25,.5,.75))
quantiles

# Construct the categorical features based on the quantiles
training[training==0] <- 0
training[training>0 & training <= 1] <- 1
training[training>1 & training <= 17] <- 2
# training[training>17 & training <= 20] <- 3
training[training>17] <- 4

# training[training==0] <- 0
# training[training>0 & training <= 1] <- 1
# training[training>1 & training <= 14] <- 2
# training[training>14 & training <= 27] <- 3
# training[training>27 & training <= 30] <- 4
# training[training>30] <- 5
# Convert the categorical into factor variables
for (i in 1:23) {
 training[,i] <- as.factor(training[,i]) 
}
for (i in 1:23) {
  names(training)[i] <- paste0(names(training)[i],'cat')
}

# The levels are not consistent across features: make them all 5
for (i in 1:23) {
  training[,i] <- factor(training[,i], levels = c("0","1","2","4"))
}

# Do the same thing as above to the validation dataset
validation <- as.data.frame(valid.NoNANoM[,7:29])



validation[validation==0] <- 0
validation[validation>0 & validation <= 1] <- 1
validation[validation>1 & validation <= 17] <- 2
# validation[validation>17 & validation <= 20] <- 3
validation[validation>17] <- 4

# validation[validation==0] <- 0
# validation[validation>0 & validation <= 1] <- 1
# validation[validation>1 & validation <= 14] <- 2
# validation[validation>14 & validation <= 27] <- 3
# validation[validation>27 & validation <= 30] <- 4
# validation[validation>30] <- 5

for (i in 1:23) {
 validation[,i] <- as.factor(validation[,i]) 
}
for (i in 1:23) {
  names(validation)[i] <- paste0(names(validation)[i],'cat')
}

for (i in 1:23) {
  validation[,i] <- factor(validation[,i], levels = c("0","1","2","4"))
}

validation$group <- valid.NoNANoM$group
training$group <- train.NoNANoM$group
```

#### Is_active Ratio
```{r}
# Obtain the app count features we want to bin
trainingIsactive <- as.data.frame(train.NoNANoM[,30:51])
# Stack the app count features into one long vector
counts <- stack(trainingIsactive)
# Calculate the quantiles
quantiles <- quantile(counts[,1], c(.25,.5,.75))
quantiles

# Construct the categorical features based on the quantiles
trainingIsactive[trainingIsactive==0] <- 0
trainingIsactive[trainingIsactive>0 & trainingIsactive <= 1] <- 1
trainingIsactive[trainingIsactive>1 & trainingIsactive <= 1.5] <- 2
# trainingIsactive[training>17 & training <= 20] <- 3
trainingIsactive[trainingIsactive>1.5] <- 4

# trainingIsactive[trainingIsactive==0] <- 0
# trainingIsactive[trainingIsactive>0 & trainingIsactive <= 1] <- 1
# trainingIsactive[trainingIsactive>1 & trainingIsactive <= 14] <- 2
# trainingIsactive[trainingIsactive>14 & trainingIsactive <= 27] <- 3
# trainingIsactive[trainingIsactive>27 & trainingIsactive <= 30] <- 4
# trainingIsactive[trainingIsactive>30] <- 5
# Convert the categorical into factor variables
for (i in 1:22) {
 trainingIsactive[,i] <- as.factor(trainingIsactive[,i]) 
}
for (i in 1:22) {
  names(trainingIsactive)[i] <- paste0(names(trainingIsactive)[i],'cat')
}

# The levels are not consistent across features: make them all 5
for (i in 1:22) {
  trainingIsactive[,i] <- factor(trainingIsactive[,i], levels = c("0","1","2","4"))
}

# Do the same thing as above to the validation dataset
validIsactive <- as.data.frame(valid.NoNANoM[,30:51])



validIsactive[validIsactive==0] <- 0
validIsactive[validIsactive>0 & validIsactive <= 1] <- 1
validIsactive[validIsactive>1 & validIsactive <= 1.5] <- 2
# validIsactive[validIsactive>17 & validIsactive <= 20] <- 3
validIsactive[validIsactive>1.5] <- 4

# validIsactive[validIsactive==0] <- 0
# validIsactive[validIsactive>0 & validIsactive <= 1] <- 1
# validIsactive[validIsactive>1 & validIsactive <= 14] <- 2
# validIsactive[validIsactive>14 & validIsactive <= 27] <- 3
# validIsactive[validIsactive>27 & validIsactive <= 30] <- 4
# validIsactive[validIsactive>30] <- 5

for (i in 1:22) {
 validIsactive[,i] <- as.factor(validIsactive[,i]) 
}
for (i in 1:22) {
  names(validIsactive)[i] <- paste0(names(validIsactive)[i],'cat')
}

for (i in 1:22) {
  validIsactive[,i] <- factor(validIsactive[,i], levels = c("0","1","2","4"))
}

```


#### Day Count
```{r}
# Obtain the day count features we want to bin
training <- as.data.frame(train.NoNANoM[,52:59])
# Stack the day count features into one long vector
counts <- stack(training)
# Calculate the quantiles
quantiles <- quantile(counts[,1], c(.25,.5,.75))
quantiles

# Construct the categorical features based on the quantiles
training[training==0] <- 0
training[training>0 & training <= 1] <- 1
training[training>1 & training <= 5] <- 2
training[training>5] <- 3

# Convert the categorical into factor variables
for (i in 1:8) {
 training[,i] <- as.factor(training[,i]) 
 names(training)[i] <- paste0(names(training)[i],'cat')
}


# Do the same thing as above to the validation dataset
validation <- as.data.frame(valid.NoNANoM[,52:59])

validation[validation==0] <- 0
validation[validation>0 & validation <= 1] <- 1
validation[validation>1 & validation <= 5] <- 2
validation[validation>5] <- 3

for (i in 1:8) {
 validation[,i] <- as.factor(validation[,i]) 
 names(validation)[i] <- paste0(names(validation)[i],'cat')
 # The levels are not consistent across features: make them all 4
 validation[,i] <- factor(validation[,i], levels = c("0","1","2","3"))
}

# fit the model with transformed categorical features
train.daycat <- training
valid.daycat <- validation
train.daycat$group <- train.NoNANoM$group
valid.daycat$group <- valid.NoNANoM$group
train.daycat$group <- as.factor(train.daycat$group)
valid.daycat$group <- as.factor(valid.daycat$group)

fit.daycat <- naiveBayes(group~., data=train.daycat)
pred.daycat<-predict(fit.daycat, valid.daycat)
summary(pred.daycat)
mean(pred.daycat!=valid.daycat$group)    # 0.8609499
probs <-predict(fit.daycat, valid.daycat, type = 'raw')
MultiLogLoss(y_pred = probs, y_true = valid.daycat$group)  # 2.469864


# fit a model using original features, compare accuracy
training <- as.data.frame(train.NoNANoM[,52:59])
training <- cbind(training, train.NoNANoM[,2])
names(training)[9] <- 'group'
validation <- as.data.frame(valid.NoNANoM[,52:59])
validation <- cbind(validation, valid.NoNANoM[,2])
names(validation)[9] <- 'group'
training$group <- as.factor(training$group)
validation$group <- as.factor(validation$group)

fit <- naiveBayes(group~., data=training)
pred <- predict(fit, validation)
summary(pred)
mean(pred!=validation$group)    # 0.9245648
probs <-predict(fit, validation, type = 'raw')
MultiLogLoss(y_pred = probs, y_true = validation$group)    # 4.4001683
```


```{r}
# try using different quantiles for different day cound feature
training <- as.data.frame(train.NoNANoM[,52:59])
training <- cbind(training, train.NoNANoM[,2])
names(training)[9] <- 'group'
validation <- as.data.frame(valid.NoNANoM[,52:59])
validation <- cbind(validation, valid.NoNANoM[,2])
names(validation)[9] <- 'group'

train.daycat2<- training
Apr30 <- training[,1]
quantile(Apr30, names=F)
Apr30[Apr30<=0] <- 0
Apr30[Apr30>0 & Apr30 <= 8] <- 1
train.daycat2[,1] <- Apr30

for (i in 2:8){
  temp <- training[,i]
  quantiles <- quantile(temp, names=F)
  q1 <- quantiles[2]
  q2 <- quantiles[3]
  q3 <- quantiles[4]
  temp[temp<=q1] <- 0
  temp[temp>q1 & temp <= q2] <- 1
  temp[temp>q2 & temp <= q3] <- 2
  temp[temp>q3] <- 3
  train.daycat2[,i] <- temp
}

for (i in 1:8) {
 train.daycat2[,i] <- as.factor(train.daycat2[,i]) 
 names(train.daycat2)[i] <- paste0(names(training)[i],'cat')
 # The levels are not consistent across features: make them all 4
 train.daycat2[,i] <- factor(train.daycat2[,i], levels = c("0","1","2","3"))
}


# transform validation dataset
validation <- as.data.frame(valid.NoNANoM[,52:59])
validation <- cbind(validation, valid.NoNANoM[,2])
names(validation)[9] <- 'group'

valid.daycat2<- validation
Apr30 <- validation[,1]
quantile(Apr30, names=F)
Apr30[Apr30<=0] <- 0
Apr30[Apr30>0 & Apr30 <= 8] <- 1
valid.daycat2[,1] <- Apr30

for (i in 2:8){
  temp <- validation[,i]
  quantiles <- quantile(temp, names=F)
  q1 <- quantiles[2]
  q2 <- quantiles[3]
  q3 <- quantiles[4]
  temp[temp<=q1] <- 0
  temp[temp>q1 & temp <= q2] <- 1
  temp[temp>q2 & temp <= q3] <- 2
  temp[temp>q3] <- 3
  valid.daycat2[,i] <- temp
}

for (i in 1:8) {
 valid.daycat2[,i] <- as.factor(valid.daycat2[,i]) 
 names(valid.daycat2)[i] <- paste0(names(validation)[i],'cat')
 # The levels are not consistent across features: make them all 4
 valid.daycat2[,i] <- factor(valid.daycat2[,i], levels = c("0","1","2","3"))
}



# fit the model with transformed categorical features
train.daycat2$group <- as.factor(train.daycat2$group)
valid.daycat2$group <- as.factor(valid.daycat2$group)

fit.daycat2 <- naiveBayes(group~., data=train.daycat2)
pred.daycat2 <- predict(fit.daycat2, valid.daycat2)
summary(pred.daycat2)
#   F23- F24-26 F27-28 F29-32 F33-42   F43+   M22- M23-26 M27-28 M29-31 M32-38   M39+ 
#      0      0      0      3    244      0   1659    511      0      2    763   1471 
mean(pred.daycat2!=valid.daycat2$group)    # 0.8613798
probs <-predict(fit.daycat2, valid.daycat2, type = 'raw')
MultiLogLoss(y_pred = probs, y_true = valid.daycat2$group)  # 2.469194
```

```{r}
# summary
# use original day counts
#   F23- F24-26 F27-28 F29-32 F33-42   F43+   M22- M23-26 M27-28 M29-31 M32-38   M39+ 
#   3994      0      0     65     64     77     35     92     14     42     73    197 
# misclassification rate: 0.9245648
# logloss: 4.400168


# transformed features with same quantiles
#   F23- F24-26 F27-28 F29-32 F33-42   F43+   M22- M23-26 M27-28 M29-31 M32-38   M39+ 
#      3      1      0      2    246      0   1663    492      0      3    697   1546 
# misclassification rate: 0.8609499
# logloss: 2.469864


# transformed features with different quantiles
#   F23- F24-26 F27-28 F29-32 F33-42   F43+   M22- M23-26 M27-28 M29-31 M32-38   M39+ 
#      0      0      0      3    244      0   1659    511      0      2    763   1471 
# misclassification rate: 0.8613798
# logloss: 2.469194
```


```{r}
traincateg<-cbind(training, trainingIsactive)
validcateg<-cbind(validation, validIsactive)
traincateg$group <- as.factor(traincateg$group)
validcateg$group <- as.factor(validcateg$group)

fit.nb1<-naiveBayes(group~., data=traincateg)
pred.nb1<-predict(fit.nb1, validcateg)
summary(pred.nb1)
mean(pred.nb1!=validcateg$group)   # 0.8540726

#log-loss
pred.nb1probs <-predict(fit.nb1, validcateg, type = 'raw')
pred.nb1probsdat <- data.frame(validcateg$group, pred.nb1probs)
logloss <- vector(length = length(pred.nb1probsdat$validcateg.group))
for (i in 1:length(pred.nb1probsdat$validcateg.group)) {
  clas=grep(str_split(paste(pred.nb1probsdat$validcateg.group[i]), '-')[[1]][1], names(pred.nb1probsdat))
  logloss[i] = log(pred.nb1probsdat[i,clas])
}
-mean(logloss)
```

### RF
```{r}
set.seed(1223)
fit.rf <- randomForest(as.factor(group)~., data = traincateg, na.action = na.omit)

rf.pred <- predict(fit.rf, newdata=validcateg)
table(rf.pred, validcateg$group)
mean(rf.pred[is.na(rf.pred)==FALSE]!=validcateg$group[is.na(rf.pred)==FALSE])

predrfprobs <-predict(fit.rf, validcateg, type = 'prob')
predrfprobsdat <- data.frame(validcateg$group, predrfprobs)
logloss <- vector(length = length(predrfprobsdat$validcateg.group))
for (i in 1:length(predrfprobsdat$validcateg.group)) {
  clas=grep(str_split(paste(predrfprobsdat$validcateg.group[i]), '-')[[1]][1], names(predrfprobsdat))
  logloss[i] = log(predrfprobsdat[i,clas])
}
-mean(logloss[is.infinite(logloss)==FALSE])

ginis<-importance(fit.rf)
ginis<-data.frame('gini'=ginis[,1], 'categ' = rownames(ginis))
arrange(ginis, desc(gini))
```

###SVM
```{r}
fit.svm <- svm(as.factor(group) ~ . , traincateg, probability=TRUE)
pred_svm <- predict(fit.svm, validcateg)
mean(as.character(pred_svm) != as.character(validcateg$group))
table(pred_svm, validcateg$group)

predsvmprobs <-predict(fit.svm, validcateg, probability = T)
predsvmprobs <- attr(predsvmprobs, 'probabilities')
predsvmprobsdat <- data.frame(validcateg$group, predsvmprobs)
logloss <- vector(length = length(predsvmprobsdat$validcateg.group))
for (i in 1:length(predsvmprobsdat$validcateg.group)) {
  clas=grep(str_split(paste(predsvmprobsdat$validcateg.group[i]), '-')[[1]][1], names(predsvmprobsdat))
  logloss[i] = log(predsvmprobsdat[i,clas])
}
-mean(logloss)
```

### Logistic
```{r}
train_log<- traincateg
train_log<-na.omit(train_log)
valid_log<-validcateg
valid_log<-na.omit(valid_log)

model_log <- multinom(group ~ ., data = traincateg, MaxNWts = 100000, model = TRUE, probability = TRUE)
pred_log<-predict(model_log,valid_log)
pred_log_score<-predict (model_log,valid_log, 'probs')
mean(as.character(pred_log) != as.character(valid_log$group))
table(pred_log, valid_log$group)
# coef(model_log)

predlogprobsdat <- data.frame(validcateg$group, pred_log_score)
logloss <- vector(length = length(predlogprobsdat$validcateg.group))
for (i in 1:length(predlogprobsdat$validcateg.group)) {
  clas=grep(str_split(paste(predlogprobsdat$validcateg.group[i]), '-')[[1]][1], names(predlogprobsdat))
  logloss[i] = log(predlogprobsdat[i,clas])
}
-mean(logloss)
```

### Performance
```{r results='asis'}
performancecateg <-data.frame('features' = c('App Ct categorical features','App Ct categorical features','App Ct categorical features','App Ct categorical features'), 'Model' = c('NB','RF','SVM','Logistic'), 'Logloss' = c(2.711981,2.499703,2.307586,2.300363), 'Misclass' = c( 0.8441865,0.8295723,0.8269933,0.815173))
kable(performancecateg, caption = 'Performance of App Ct Categorical Variables') %>%
  kable_styling(bootstrap_options = c("striped", "bordered", "responsive", "condensed"), full_width = F)
```

```{r results='asis'}
performancecateg2 <-data.frame('features' = c('Is_Active & App Ct Categ','Is_Active & App Ct Categ','Is_Active & App Ct Categ','Is_Active & App Ct Categ'), 'Model' = c('NB','RF','SVM','Logistic'), 'Logloss' = c(2.713002,2.422743,2.309568,2.315649), 'Misclass' = c(0.8396733,0.8334408,0.8280679,0.8166774))
kable(performancecateg2, caption = 'Performance of Is_active&App Ct Categorical Variables') %>%
  kable_styling(bootstrap_options = c("striped", "bordered", "responsive", "condensed"), full_width = F)
```

### Predict gender and age separately
```{r}
# Predict gender only
group <- traincateg$group
gender <- substr(group, 1, 1)
traingender <- cbind(traincateg, gender)

group <- validcateg$group
gender <- substr(group, 1, 1)
validgender <- cbind(validcateg, gender)


traingender$gender <- as.factor(traingender$gender)
validgender$gender <- as.factor(validgender$gender)
names(traingender)[18] <- 'socialnetworking.appCt'
names(validgender)[18] <- 'socialnetworking.appCt'
fitgender<-naiveBayes(gender~., data=traingender[,-24])
predgender<-predict(fitgender, validgender[,-24])
summary(predgender)
mean(predgender!=validgender$gender)    # 0.4167204
validgender <- cbind(validgender, gender.predict=predgender)


# predict age further
# separate male and female groups
train.female <- traingender[traingender$gender=='F',]   # 6452
train.male <- traingender[traingender$gender=='M',]     # 12142
valid.female <- validgender[validgender$gender=='F',]   # 1571
valid.male <- validgender[validgender$gender=='M',]     # 3082

# predict age for female
group <- train.female$group
age <- substr(group, 2, 10)
train.female <- cbind(train.female, age)

group <- valid.female$group
age <- substr(group, 2, 10)
valid.female <- cbind(valid.female, age)

train.female$age <- as.factor(train.female$age)
valid.female$age <- as.factor(valid.female$age)

fit.female.age <- naiveBayes(age~., data=train.female[,-c(24,25)])
pred.female.age <- predict(fit.female.age, valid.female[,-c(24,25,26)])
summary(pred.female.age)
mean(pred.female.age!=valid.female$age)    # 0.7536601
valid.female <- cbind(valid.female, age.predict=pred.female.age)


# predict age for female
group <- train.male$group
age <- substr(group, 2, 10)
train.male <- cbind(train.male, age)

group <- valid.male$group
age <- substr(group, 2, 10)
valid.male <- cbind(valid.male, age)

train.male$age <- as.factor(train.male$age)
valid.male$age <- as.factor(valid.male$age)

fit.male.age <- naiveBayes(age~., data=train.male[,-c(24,25)])
pred.male.age <- predict(fit.male.age, valid.male[,-c(24,25,26)])
summary(pred.male.age)
mean(pred.male.age!=valid.male$age)    # 0.7787151
valid.male <- cbind(valid.male, age.predict=pred.male.age)

# overall misclassification rate
valid.gender.age <- rbind(valid.female, valid.male)
group.predict <- paste(valid.gender.age$gender.predict, valid.gender.age$age.predict, sep='')
mean(group.predict!=valid.gender.age$group)    # 0.8540726
```

### Add location in the model
```{r}
# location with kNN imputation
train.categ.loc <- cbind(traincateg, train.final[,3:4])
valid.categ.loc <- cbind(validcateg, valid.final[,3:4])
train.categ.loc$group <- as.factor(train.categ.loc$group)
train.categ.loc$group <- as.factor(train.categ.loc$group)

fit.categ.loc <- naiveBayes(group~., data=train.categ.loc)
pred.categ.loc <- predict(fit.categ.loc, valid.categ.loc)
summary(pred.categ.loc)
mean(pred.categ.loc!=valid.categ.loc$group)   # 0.8538577
probs <-predict(fit.categ.loc, valid.categ.loc, type = 'raw')
MultiLogLoss(y_pred = probs, y_true = valid.categ.loc$group)    # 3.103822

# original location data with half missing values
train.categ.loc <- cbind(traincateg, train.NoNANoM[,3:4])
valid.categ.loc <- cbind(validcateg, valid.NoNANoM[,3:4])
train.categ.loc$group <- as.factor(train.categ.loc$group)
train.categ.loc$group <- as.factor(train.categ.loc$group) 

fit.categ.loc <- naiveBayes(group~., data=train.categ.loc)
pred.categ.loc <- predict(fit.categ.loc, valid.categ.loc)
summary(pred.categ.loc)
mean(pred.categ.loc!=valid.categ.loc$group)   # 0.8527832
probs <-predict(fit.categ.loc, valid.categ.loc, type = 'raw')
MultiLogLoss(y_pred = probs, y_true = valid.categ.loc$group)    # 3.071154
```

### select categorical count features with most predictive power
```{r}
misclasify <- rep(0,23)
logloss <- rep(0,23)
for (i in 1:23){
  train.temp <- traincateg[,c(i,24)]
  valid.temp <- validcateg[,c(i,24)]
  fit <- naiveBayes(group~., data=train.temp)
  pred <- predict(fit, valid.temp)
  misclasify[i] <- mean(pred!=valid.temp$group)
  # print(names(validcateg)[i])
  # print(misclasify[i])
  # print(summary(pred))
  probs <-predict(fit, valid.temp, type = 'raw')
  logloss[i] <- MultiLogLoss(y_pred = probs, y_true = valid.temp$group)
}
result <- cbind(names(validcateg)[1:23], misclasify, logloss)
result
```

```{r}
# feature selection
train.NB.3cat <- traincateg[,c(7,12,23,24)]
valid.NB.3cat <- validcateg[,c(7,12,23,24)]
train.NB.3cat$group <- as.factor(train.NB.3cat$group)
valid.NB.3cat$group <- as.factor(valid.NB.3cat$group)

fit.NB.3cat <- naiveBayes(group~., data=train.NB.3cat)
pred.NB.3cat <- predict(fit.NB.3cat, valid.NB.3cat)
summary(pred.NB.3cat)
mean(pred.NB.3cat!=valid.NB.3cat$group)
probs.NB.3cat <-predict(fit.NB.3cat, valid.NB.3cat, type = 'raw')     # 0.8486998
MultiLogLoss(y_pred = probs.NB.3cat, y_true = valid.NB.3cat$group)    # 2.389098
# "finance.appCtcat"      2.37625778986919
# "lifestyle.appCtcat"    2.38209164080928
# "vehicle.appCtcat"      2.38140327531365
```

```{r}
misclasify2 <- rep(0,65)
logloss2 <- rep(0,65)
train.NoNANoM <- as.data.frame(train.NoNANoM)
valid.NoNANoM <- as.data.frame(valid.NoNANoM)
names(train.NoNANoM)[c(24,46)] <- c("socialnetworking.appct", "socialnetworking.isactiveRat")
names(valid.NoNANoM)[c(24,46)] <- c("socialnetworking.appct", "socialnetworking.isactiveRat")

for (i in 3:67){
  train.temp <- train.NoNANoM[,c(i,2)]
  valid.temp <- valid.NoNANoM[,c(i,2)]
  train.temp$group <- as.factor(train.temp$group)
  valid.temp$group <- as.factor(valid.temp$group)
  fit <- naiveBayes(group~., data=train.temp)
  pred <- predict(fit, valid.temp)
  misclasify2[i-2] <- mean(pred!=valid.temp$group)
  # print(names(valid.NoNANoM)[i])
  # print(misclasify2[i-2])
  # print(summary(pred))
  probs <-predict(fit, valid.temp, type = 'raw')
  logloss2[i-2] <- MultiLogLoss(y_pred = probs, y_true = valid.temp$group)
}
result2 <- cbind(names(valid.NoNANoM)[3:67], misclasify2, logloss2)
result2
 
```

```{r}
# select features in the original dataset with misclassification rate <0.87
features <- misclasify2[misclasify2[,2]<0.87,1]   # 30 features
features <- misclasify2[misclasify2[,2]<0.86,1]   # 18 features
features <- c(features, 'group')

train.NBreduce <- train.NoNANoM[,features]
valid.NBreduce <- valid.NoNANoM[,features]
train.NBreduce$group <- as.factor(train.NBreduce$group)
valid.NBreduce$group <- as.factor(valid.NBreduce$group)
fit.NBreduce <- naiveBayes(group~., data=train.NBreduce)
pred.NBreduce <- predict(fit, valid.NBreduce)
summary(pred.NBreduce)
mean(pred.NBreduce!=valid.NBreduce$group)
```

## Categorical to Group


```{r}
counterf23 <- NULL
counterF24 <- NULL
counterF27 <- NULL
counterF29 <- NULL
counterF33 <- NULL
counterF43 <- NULL
counterM22 <- NULL
counterM23 <- NULL
counterM27 <- NULL
counterM29 <- NULL
counterM32 <- NULL
counterM39 <- NULL

bookf23 <- 0
bookF24 <- 0
bookF27 <- 0
bookF29 <- 0
bookF33 <- 0
bookF43 <- 0
bookM22 <- 0
bookM23 <- 0
bookM27 <- 0
bookM29 <- 0
bookM32 <- 0
bookM39 <- 0

for (i in 1:18594) {
  counterf23 = ifelse(traincateg[i,1]=='0' & traincateg[i,24]=='F23-',1,0)
  counterf24 = ifelse(traincateg[i,1]=='0' & traincateg[i,24]=='F24-26',1,0)
  counterF27 = ifelse(traincateg[i,1]=='0' & traincateg[i,24]=='F27-28',1,0)
  counterF29 = ifelse(traincateg[i,1]=='0' & traincateg[i,24]=='F29-32',1,0)
  counterF33 = ifelse(traincateg[i,1]=='0' & traincateg[i,24]=='F33-42',1,0)
  counterF43 = ifelse(traincateg[i,1]=='0' & traincateg[i,24]=='F43+',1,0)
  counterM22 = ifelse(traincateg[i,1]=='0' & traincateg[i,24]=='M22-',1,0)
  counterM23 = ifelse(traincateg[i,1]=='0' & traincateg[i,24]=='M23-26',1,0)
  counterM27 = ifelse(traincateg[i,1]=='0' & traincateg[i,24]=='M27-28',1,0)
  counterM29 = ifelse(traincateg[i,1]=='0' & traincateg[i,24]=='M29-31',1,0)
  counterM32 = ifelse(traincateg[i,1]=='0' & traincateg[i,24]=='M32-38',1,0)
  counterM39 = ifelse(traincateg[i,1]=='0' & traincateg[i,24]=='M39+',1,0)
  bookf23 = bookf23 + counterf23
  bookF24 = bookF24 + counterf24
  bookF27 = bookF27 + counterF27
  bookF29 = bookF29 + counterF29
  bookF33 = bookF33 + counterF33
  bookF43 = bookF43 + counterF43
  bookM22 = bookM22 + counterM22
  bookM23 = bookM23 + counterM23
  bookM27 = bookM27 + counterM27
  bookM29 = bookM29 + counterM29
  bookM32 = bookM32 + counterM32
  bookM39 = bookM39 + counterM39
}
bookcts <- c(bookf23,bookF24,bookF27,bookF29,bookF33,bookF43,bookM22,bookM23,bookM27,bookM29,bookM32,bookM39)
bookcts <- data.frame('bookcts' = bookcts, 'group'=c('F23-','F24-26','F27-28','F29-32','F33-42','F43+','M22-','M23-26','M27-28','M29-31','M32-38','M39+'))

ggplot(data = bookcts, aes(x=group,y=bookcts)) +
  geom_bar(stat = 'identity')
```


##Try all features
```{r}
traintotal <- cbind(traincateg[,1:23],train.NoNANoM[,-c(1,3,4,66,67)], train.final[,c(3,4)])
validtotal <- cbind(validcateg[,1:23],valid.NoNANoM[,-c(1,3,4,66,67)],valid.final[,c(3,4)])
traintotal$group <- as.factor(traintotal$group)
validtotal$group <- as.factor(validtotal$group)
```
### Naive Bayes
```{r}
fit.nb<-naiveBayes(group~., data=traintotal)
nb.pred<-predict(fit.nb, validtotal)
summary(nb.pred)
mean(nb.pred!=validtotal$group)

#log-loss
prednbprobs <-predict(fitnb, validtotal, type = 'raw')
prednbprobsdat <- data.frame(validtotal$group, prednbprobs)
logloss <- vector(length = length(prednbprobsdat$validtotal.group))
for (i in 1:length(prednbprobsdat$validtotal.group)) {
  clas=grep(str_split(paste(prednbprobsdat$validtotal.group[i]), '-')[[1]][1], names(prednbprobsdat))
  logloss[i] = log(prednbprobsdat[i,clas])
}
-mean(logloss[is.infinite(logloss)==FALSE])
# 2.953445

MultiLogLoss(y_pred = prednbprobs, y_true = validtotal$group)
```

### RF
```{r}
set.seed(1223)
fit.rf <- randomForest(as.factor(group)~., data = traintotal, na.action = na.omit)

rf.pred <- predict(fit.rf, newdata=validtotal)
table(rf.pred, validtotal$group)
mean(rf.pred[is.na(rf.pred)==FALSE]!=validtotal$group[is.na(rf.pred)==FALSE])

predrfprobs <-predict(fit.rf, validtotal, type = 'prob')
predrfprobsdat <- data.frame(validtotal$group, predrfprobs)
logloss <- vector(length = length(predrfprobsdat$validtotal.group))
for (i in 1:length(predrfprobsdat$validtotal.group)) {
  clas=grep(str_split(paste(predrfprobsdat$validtotal.group[i]), '-')[[1]][1], names(predrfprobsdat))
  logloss[i] = log(predrfprobsdat[i,clas])
}
-mean(logloss)
```


### SVM
```{r}
fit.svm <- svm(as.factor(group) ~ . , traintotal, probability=TRUE)
pred_svm <- predict(fit.svm, validtotal)
mean(as.character(pred_svm) != as.character(validtotal$group))
table(pred_svm, validtotal$group)

predsvmprobs <-predict(fit.svm, validtotal, probability = T)
predsvmprobs <- attr(predsvmprobs, 'probabilities')
predsvmprobsdat <- data.frame(validtotal$group, predsvmprobs)
logloss <- vector(length = length(predsvmprobsdat$validtotal.group))
for (i in 1:length(predsvmprobsdat$validtotal.group)) {
  clas=grep(str_split(paste(predsvmprobsdat$validtotal.group[i]), '-')[[1]][1], names(predsvmprobsdat))
}
  logloss[i] = log(predsvmprobsdat[i,clas])
```



```{r}
require(nnet)
model_log <- multinom(group ~ ., data = traintotal, MaxNWts = 1000000, model = TRUE)
pred_log<-predict(model_log,valid_log)
pred_log_score<-predict (model_log,valid_log, 'probs')
mean(as.character(pred_log) != as.character(valid_log$group))
table(pred_log, valid_log$group)

predlogprobsdat <- data.frame(validtotal$group, pred_log_score)
logloss <- vector(length = length(predlogprobsdat$validtotal.group))
for (i in 1:length(predlogprobsdat$validtotal.group)) {
  clas=grep(str_split(paste(predlogprobsdat$validtotal.group[i]), '-')[[1]][1], names(predlogprobsdat))
  logloss[i] = log(predlogprobsdat[i,clas])
}
-mean(logloss)
```

### Performance
```{r results='asis'}
performanceall <-data.frame('features' = c('All features','All features','All features','All features'), 'Model' = c('NB','RF','SVM','Logistic'), 'Logloss' = c(21.03885,2.267561,2.271811,2.373419), 'Misclass' = c( 0.9153234,0.8035676,0.8065764,0.820331))

kable(performanceall, caption = 'Performance Using All Variables') %>%
  kable_styling(bootstrap_options = c("striped", "bordered", "responsive", "condensed"), full_width = F)
```













## Second -- Taking out the least important features
```{r}
traintotal2 <- traintotal[,-c(2,16,7,42,57,45,19,8,34,72)]
validtotal2 <- validtotal[,-c(2,16,7,42,57,45,19,8,34,72)]
```
### Naive Bayes
```{r}
fit.nb2<-naiveBayes(group~., data=traintotal2)
nb2.pred<-predict(fit.nb2, validtotal2)
summary(nb2.pred)
mean(nb2.pred!=validtotal2$group)

#log-loss
prednb2probs <-predict(fit.nb2, validtotal2, type = 'raw')
prednb2probsdat <- data.frame(validtotal2$group, prednb2probs)
logloss <- vector(length = length(prednb2probsdat$validtotal2.group))
for (i in 1:length(prednb2probsdat$validtotal2.group)) {
  clas=grep(str_split(paste(prednb2probsdat$validtotal2.group[i]), '-')[[1]][1], names(prednb2probsdat))
  logloss[i] = log(prednb2probsdat[i,clas])
}
-mean(logloss[is.infinite(logloss)==FALSE])


MultiLogLoss(y_pred = prednb2probs, y_true = validtotal2$group)
```

### RF

```{r}
set.seed(1223)
fit.rf2 <- randomForest(as.factor(group)~., data = traintotal2, na.action = na.omit)

rf2.pred <- predict(fit.rf2, newdata=validtotal2)
table(rf2.pred, validtotal2$group)
mean(rf2.pred[is.na(rf2.pred)==FALSE]!=validtotal2$group[is.na(rf2.pred)==FALSE])

predrf2probs <-predict(fit.rf2, validtotal2, type = 'prob')
predrf2probsdat <- data.frame(validtotal2$group, predrf2probs)
logloss <- vector(length = length(predrf2probsdat$validtotal2.group))
for (i in 1:length(predrf2probsdat$validtotal2.group)) {
  clas=grep(str_split(paste(predrf2probsdat$validtotal2.group[i]), '-')[[1]][1], names(predrf2probsdat))
  logloss[i] = log(predrf2probsdat[i,clas])
}
-mean(logloss[is.infinite(logloss)==FALSE])

ginis<-importance(fit.rf2)
ginis<-data.frame('gini'=ginis[,1], 'categ' = rownames(ginis))
arrange(ginis, desc(gini))
```

### SVM
```{r}
fit.svm2 <- svm(as.factor(group) ~ . , traintotal2, probability=TRUE)
pred_svm2 <- predict(fit.svm2, validtotal2)
mean(as.character(pred_svm2) != as.character(validtotal2$group))
table(pred_svm2, validtotal2$group)

predsvm2probs <-predict(fit.svm2, validtotal2, probability = T)
predsvm2probs <- attr(predsvm2probs, 'probabilities')
predsvm2probsdat <- data.frame(validtotal2$group, predsvm2probs)
logloss <- vector(length = length(predsvm2probsdat$validtotal2.group))
for (i in 1:length(predsvm2probsdat$validtotal2.group)) {
  clas=grep(str_split(paste(predsvm2probsdat$validtotal2.group[i]), '-')[[1]][1], names(predsvm2probsdat))
  logloss[i] = log(predsvm2probsdat[i,clas])
}
-mean(logloss)
```

### Logistic
```{r}
train_log2<- traintotal2
train_log2<-na.omit(train_log2)
valid_log2<-validtotal2
valid_log2<-na.omit(valid_log2)

require(nnet)
model_log2 <- multinom(group ~ ., data = traintotal2, MaxNWts = 1000000, model = TRUE)
pred_log2<-predict(model_log2,valid_log2)
pred_log2_score<-predict (model_log2,valid_log2, 'probs')
mean(as.character(pred_log2) != as.character(valid_log2$group))
table(pred_log2, valid_log2$group)

predlog2probsdat <- data.frame(validtotal2$group, pred_log2_score)
logloss <- vector(length = length(predlog2probsdat$validtotal2.group))
for (i in 1:length(predlog2probsdat$validtotal2.group)) {
  clas=grep(str_split(paste(predlog2probsdat$validtotal2.group[i]), '-')[[1]][1], names(predlog2probsdat))
  logloss[i] = log(predlog2probsdat[i,clas])
}
-mean(logloss)
```

### Performance
```{r results='asis'}
performance2 <-data.frame('features' = c('Important features','Important features','Important features','Important features'), 'Model' = c('NB','RF','SVM','Logistic'), 'Logloss' = c(21.33751, 2.267722,2.272564,2.373592), 'Misclass' = c(0.913819,0.7964754,0.8037825,0.812594))

kable(performance2, caption = 'Performance Using Selected Variables') %>%
  kable_styling(bootstrap_options = c("striped", "bordered", "responsive", "condensed"), full_width = F)
```

### New Feature Ideas